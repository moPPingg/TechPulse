<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Time Series Fundamentals</title>
  <style>
    :root {
      --bg: #fafafa;
      --text: #1a1a1a;
      --muted: #555;
      --code-bg: #f0f0f0;
      --border: #e0e0e0;
      --accent: #2563eb;
      --blockquote: #e8eef7;
    }
    @media (prefers-color-scheme: dark) {
      :root {
        --bg: #1a1a1a;
        --text: #e4e4e4;
        --muted: #a0a0a0;
        --code-bg: #2d2d2d;
        --border: #333;
        --accent: #60a5fa;
        --blockquote: #1e293b;
      }
    }
    * { box-sizing: border-box; }
    body {
      font-family: "Segoe UI", "Source Sans 3", system-ui, sans-serif;
      line-height: 1.65;
      color: var(--text);
      background: var(--bg);
      max-width: 900px;
      margin: 0 auto;
      padding: 2rem 1.5rem;
    }
    h1 { font-size: 1.85rem; margin-top: 0; border-bottom: 2px solid var(--border); padding-bottom: 0.5rem; }
    h2 { font-size: 1.4rem; margin-top: 2rem; color: var(--accent); }
    h3 { font-size: 1.15rem; margin-top: 1.5rem; }
    h1, h2, h3 { scroll-margin-top: 1rem; }
    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }
    pre, code {
      font-family: "Consolas", "Fira Code", monospace;
      background: var(--code-bg);
      border-radius: 6px;
    }
    code { padding: 0.2em 0.4em; font-size: 0.9em; }
    pre { padding: 1rem; overflow-x: auto; margin: 1rem 0; }
    pre code { padding: 0; background: none; }
    blockquote {
      border-left: 4px solid var(--accent);
      margin: 1rem 0;
      padding: 0.5rem 1rem;
      background: var(--blockquote);
      color: var(--muted);
    }
    hr { border: none; border-top: 1px solid var(--border); margin: 2rem 0; }
    ul, ol { padding-left: 1.5rem; }
    li { margin: 0.35rem 0; }
    .back-link { display: inline-block; margin-bottom: 1rem; color: var(--muted); font-size: 0.9rem; }
  </style>
</head>
<body>
  <a class="back-link" href=".">← Trở lại thư mục</a>
  <main>
<h1 id="time-series-fundamentals">Time Series Fundamentals</h1>
<h2 id="hieu-ac-thu-cua-du-lieu-chuoi-thoi-gian">Hiểu đặc thù của dữ liệu chuỗi thời gian</h2>
<hr />
<h2 id="muc-luc">Mục lục</h2>
<ol>
<li><a href="#1-time-series-là-gì">Time Series là gì?</a></li>
<li><a href="#2-autocorrelation-acf-pacf">Autocorrelation, ACF, PACF</a></li>
<li><a href="#3-lag-features-vs-rolling-features">Lag Features vs Rolling Features</a></li>
<li><a href="#4-train-test-split-cho-time-series">Train-Test Split cho Time Series</a></li>
<li><a href="#5-walk-forward-validation-research-grade">Walk-Forward Validation (Research-Grade)</a></li>
<li><a href="#6-lookahead-bias">Lookahead Bias</a></li>
<li><a href="#7-stationarity">Stationarity</a></li>
<li><a href="#8-differencing-và-transformations">Differencing và Transformations</a></li>
<li><a href="#9-mean-reversion-vs-momentum">Mean-Reversion vs Momentum</a></li>
<li><a href="#10-forecasting-metrics">Forecasting Metrics</a></li>
<li><a href="#11-multi-step-forecasting">Multi-Step Forecasting</a></li>
<li><a href="#12-bài-tập-thực-hành">Bài tập thực hành</a></li>
</ol>
<hr />
<h2 id="1-time-series-la-gi">1. TIME SERIES LÀ GÌ?</h2>
<h3 id="inh-nghia">Định nghĩa</h3>
<p><strong>Time Series = Dữ liệu được thu thập theo thứ tự thời gian</strong></p>
<p>Mỗi điểm dữ liệu gắn với một thời điểm cụ thể, và thứ tự này quan trọng.</p>
<h3 id="vi-du">Ví dụ</h3>
<p><strong>Là Time Series:</strong>
- Giá cổ phiếu hàng ngày
- Nhiệt độ hàng giờ
- Doanh số bán hàng hàng tháng</p>
<p><strong>Không phải Time Series:</strong>
- Chiều cao của học sinh trong lớp
- Giá nhà ở các quận khác nhau</p>
<h3 id="ac-iem-quan-trong">Đặc điểm quan trọng</h3>
<p><strong>1. Thứ tự thời gian (Temporal Ordering):</strong></p>
<pre><code>KHÔNG THỂ shuffle data!

Sai:  [2024-01-05, 2024-01-01, 2024-01-03]
Đúng: [2024-01-01, 2024-01-02, 2024-01-03]
</code></pre>
<p><strong>2. Phụ thuộc thời gian (Temporal Dependence):</strong></p>
<pre><code>Giá hôm nay phụ thuộc vào giá hôm qua
→ Cần features từ quá khứ (lagged features)
→ Cần models có &quot;memory&quot; (LSTM, ARIMA)
</code></pre>
<p><strong>3. Trend và Seasonality:</strong></p>
<pre><code>Trend: Xu hướng dài hạn (tăng/giảm)
Seasonality: Pattern lặp lại theo chu kỳ (tuần, tháng, năm)
</code></pre>
<hr />
<h2 id="2-autocorrelation-acf-pacf">2. AUTOCORRELATION, ACF, PACF</h2>
<h3 id="21-autocorrelation-la-gi">2.1. Autocorrelation là gì?</h3>
<p><strong>Định nghĩa:</strong> Tương quan của chuỗi với chính nó ở các thời điểm khác nhau (lags).</p>
<p><strong>Ý tưởng:</strong></p>
<pre><code>Autocorrelation lag-1: Correlation giữa y(t) và y(t-1)
Autocorrelation lag-5: Correlation giữa y(t) và y(t-5)
</code></pre>
<h3 id="vi-du-truc-quan">Ví dụ trực quan</h3>
<p><strong>Positive Autocorrelation (Momentum):</strong></p>
<pre><code>Nếu hôm nay tăng → Ngày mai có xu hướng tăng

Day 1: +2%
Day 2: +1.8%  ← Cùng chiều
Day 3: +1.5%  ← Cùng chiều
Day 4: +1.2%  ← Cùng chiều

→ Chuỗi có momentum, trend-following strategy có thể hiệu quả
</code></pre>
<p><strong>Negative Autocorrelation (Mean-Reversion):</strong></p>
<pre><code>Nếu hôm nay tăng → Ngày mai có xu hướng giảm

Day 1: +2%
Day 2: -1.5%  ← Ngược chiều
Day 3: +1.8%  ← Ngược chiều
Day 4: -1.2%  ← Ngược chiều

→ Chuỗi mean-revert, contrarian strategy có thể hiệu quả
</code></pre>
<p><strong>Zero Autocorrelation (Random Walk):</strong></p>
<pre><code>Hôm nay tăng/giảm không ảnh hưởng ngày mai

Day 1: +2%
Day 2: -0.5%  ← Ngẫu nhiên
Day 3: +1.2%  ← Ngẫu nhiên
Day 4: +0.3%  ← Ngẫu nhiên

→ Gần như không dự đoán được, efficient market
</code></pre>
<h3 id="22-acf-autocorrelation-function">2.2. ACF (Autocorrelation Function)</h3>
<p><strong>ACF(k) = Correlation giữa y(t) và y(t-k)</strong></p>
<p>Bao gồm cả tương quan trực tiếp và gián tiếp.</p>
<pre><code class="language-python">from statsmodels.graphics.tsaplots import plot_acf
import matplotlib.pyplot as plt

# Plot ACF
fig, ax = plt.subplots(figsize=(12, 5))
plot_acf(returns.dropna(), lags=20, ax=ax)
ax.set_title('Autocorrelation Function (ACF)')
ax.set_xlabel('Lag')
ax.set_ylabel('Correlation')
plt.show()
</code></pre>
<p><strong>Cách đọc ACF:</strong></p>
<pre><code>         Confidence interval (vùng xanh)
              ↓
    │  ████████ lag 1 (significant - vượt ra ngoài)
    │  ███      lag 2
    │  ██       lag 3
    │  █        lag 4
    │  ─        lag 5 (không significant - trong vùng xanh)
    └─────────────────────

Bar vượt ra ngoài vùng xanh → Autocorrelation có ý nghĩa thống kê
</code></pre>
<h3 id="23-pacf-partial-autocorrelation-function">2.3. PACF (Partial Autocorrelation Function)</h3>
<p><strong>PACF(k) = Correlation trực tiếp giữa y(t) và y(t-k), loại bỏ ảnh hưởng của các lags trung gian.</strong></p>
<p><strong>Sự khác biệt:</strong></p>
<pre><code>ACF(3):  Correlation y(t) với y(t-3)
         Bao gồm: y(t) → y(t-1) → y(t-2) → y(t-3) (gián tiếp)

PACF(3): Correlation y(t) với y(t-3) trực tiếp
         Loại bỏ ảnh hưởng của y(t-1), y(t-2)
</code></pre>
<pre><code class="language-python">from statsmodels.graphics.tsaplots import plot_pacf

# Plot PACF
fig, ax = plt.subplots(figsize=(12, 5))
plot_pacf(returns.dropna(), lags=20, ax=ax, method='ywm')
ax.set_title('Partial Autocorrelation Function (PACF)')
plt.show()
</code></pre>
<h3 id="24-dung-acfpacf-e-chon-model">2.4. Dùng ACF/PACF để chọn Model</h3>
<table>
<thead>
<tr>
<th>Process</th>
<th>ACF</th>
<th>PACF</th>
<th>Ví dụ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>AR(p)</strong></td>
<td>Decay dần</td>
<td>Cuts off sau lag p</td>
<td>AR(2): PACF significant ở lag 1,2, sau đó = 0</td>
</tr>
<tr>
<td><strong>MA(q)</strong></td>
<td>Cuts off sau lag q</td>
<td>Decay dần</td>
<td>MA(2): ACF significant ở lag 1,2, sau đó = 0</td>
</tr>
<tr>
<td><strong>ARMA</strong></td>
<td>Decay dần</td>
<td>Decay dần</td>
<td>Cả hai đều decay</td>
</tr>
</tbody>
</table>
<p><strong>Ví dụ thực tế:</strong></p>
<pre><code class="language-python"># ACF: Significant tại lag 1, cuts off
# PACF: Decay dần
# → Gợi ý: MA(1) hoặc ARIMA(0,d,1)

# ACF: Decay dần
# PACF: Significant tại lag 1, 2, cuts off
# → Gợi ý: AR(2) hoặc ARIMA(2,d,0)
</code></pre>
<h3 id="25-y-nghia-trong-trading">2.5. Ý nghĩa trong Trading</h3>
<pre><code>High positive autocorrelation (lag 1-5):
→ Momentum strategy có thể hiệu quả
→ Trend-following models

High negative autocorrelation:
→ Mean-reversion strategy có thể hiệu quả
→ Contrarian models

Near-zero autocorrelation:
→ Thị trường gần efficient
→ Khó dự đoán từ giá quá khứ
→ Cần thêm features khác (volume, sentiment)
</code></pre>
<hr />
<h2 id="3-lag-features-vs-rolling-features">3. LAG FEATURES VS ROLLING FEATURES</h2>
<h3 id="31-lag-features">3.1. Lag Features</h3>
<p><strong>Định nghĩa:</strong> Giá trị của biến ở các thời điểm trước đó.</p>
<p><strong>Ví dụ:</strong></p>
<pre><code>t   | close | close_lag1 | close_lag5
----|-------|------------|------------
1   | 100   | NaN        | NaN
2   | 102   | 100        | NaN
3   | 105   | 102        | NaN
4   | 103   | 105        | NaN
5   | 108   | 103        | NaN
6   | 110   | 108        | 100
7   | 112   | 110        | 102
</code></pre>
<p><strong>Code:</strong></p>
<pre><code class="language-python"># Tạo lag features
df['close_lag1'] = df['close'].shift(1)   # Giá hôm qua
df['close_lag5'] = df['close'].shift(5)   # Giá 5 ngày trước
df['return_lag1'] = df['return'].shift(1) # Return hôm qua

# Multiple lags
for lag in [1, 2, 3, 5, 10, 20]:
    df[f'close_lag{lag}'] = df['close'].shift(lag)
</code></pre>
<p><strong>Khi nào dùng:</strong>
- Khi muốn biết giá trị cụ thể tại thời điểm quá khứ
- AR models (AutoRegressive)
- Simple baseline predictions</p>
<h3 id="32-rolling-features">3.2. Rolling Features</h3>
<p><strong>Định nghĩa:</strong> Thống kê tính trên một window di chuyển.</p>
<p><strong>Ví dụ:</strong></p>
<pre><code>t   | close | ma_3 (rolling mean) | std_3 (rolling std)
----|-------|---------------------|---------------------
1   | 100   | NaN                 | NaN
2   | 102   | NaN                 | NaN
3   | 105   | 102.33              | 2.52
4   | 103   | 103.33              | 1.53
5   | 108   | 105.33              | 2.52
6   | 110   | 107.00              | 3.61
</code></pre>
<p><strong>Code:</strong></p>
<pre><code class="language-python"># Rolling statistics
df['ma_20'] = df['close'].rolling(window=20).mean()      # Moving average 20 ngày
df['std_20'] = df['close'].rolling(window=20).std()      # Rolling std
df['min_20'] = df['close'].rolling(window=20).min()      # Rolling min
df['max_20'] = df['close'].rolling(window=20).max()      # Rolling max

# Rolling với shift (quan trọng để tránh lookahead)
df['ma_20'] = df['close'].rolling(window=20).mean().shift(1)  # Chỉ dùng data đến hôm qua
</code></pre>
<p><strong>Khi nào dùng:</strong>
- Smoothing, trend detection
- Volatility estimation
- Support/Resistance levels
- Technical indicators (RSI, MACD, Bollinger Bands)</p>
<h3 id="33-so-sanh">3.3. So sánh</h3>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Lag Features</th>
<th>Rolling Features</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ý nghĩa</strong></td>
<td>Giá trị cụ thể tại t-k</td>
<td>Thống kê trên window</td>
</tr>
<tr>
<td><strong>Thông tin</strong></td>
<td>Point-in-time</td>
<td>Aggregated</td>
</tr>
<tr>
<td><strong>Use case</strong></td>
<td>AR models, discrete signals</td>
<td>Trend, volatility</td>
</tr>
<tr>
<td><strong>Memory</strong></td>
<td>Ít tính toán</td>
<td>Cần tính toán window</td>
</tr>
<tr>
<td><strong>Ví dụ</strong></td>
<td>close_lag5 = 100</td>
<td>ma_5 = 103.4</td>
</tr>
</tbody>
</table>
<h3 id="34-ket-hop-ca-hai">3.4. Kết hợp cả hai</h3>
<pre><code class="language-python"># Feature engineering thực tế: kết hợp cả lag và rolling

# Lag features
df['return_lag1'] = df['return'].shift(1)
df['return_lag5'] = df['return'].shift(5)

# Rolling features (shift để tránh lookahead)
df['ma_20'] = df['close'].rolling(20).mean().shift(1)
df['volatility_20'] = df['return'].rolling(20).std().shift(1)

# Derived features
df['price_vs_ma20'] = df['close'].shift(1) / df['ma_20'] - 1  # % distance from MA
df['momentum_5'] = df['close'].shift(1) / df['close'].shift(6) - 1  # 5-day momentum
</code></pre>
<hr />
<h2 id="4-train-test-split-cho-time-series">4. TRAIN-TEST SPLIT CHO TIME SERIES</h2>
<h3 id="41-tai-sao-khong-uoc-random-split">4.1. Tại sao không được Random Split?</h3>
<pre><code>Random Split (SAI cho time series):

Data:    [Jan][Feb][Mar][Apr][May][Jun][Jul][Aug][Sep]
Train:   [Jan][   ][Mar][   ][May][   ][Jul][   ][Sep]
Test:    [   ][Feb][   ][Apr][   ][Jun][   ][Aug][   ]

→ Model được train trên May → Test trên Apr
→ Dùng tương lai dự đoán quá khứ!
→ LOOKAHEAD BIAS
</code></pre>
<h3 id="42-sequential-split-simple">4.2. Sequential Split (Simple)</h3>
<pre><code>Sequential Split (ĐÚNG):

Data:    [Jan][Feb][Mar][Apr][May][Jun][Jul][Aug][Sep]
Train:   [Jan][Feb][Mar][Apr][May][Jun][Jul]
Test:                                      [Aug][Sep]

→ Luôn train trên quá khứ, test trên tương lai
</code></pre>
<p><strong>Code:</strong></p>
<pre><code class="language-python"># Simple train-test split
split_date = '2023-01-01'
train = df[df['date'] &lt; split_date]
test = df[df['date'] &gt;= split_date]

# Hoặc theo tỷ lệ
split_idx = int(len(df) * 0.8)
train = df[:split_idx]
test = df[split_idx:]
</code></pre>
<h3 id="43-walk-forward-validation">4.3. Walk-Forward Validation</h3>
<p><strong>Tại sao cần Walk-Forward?</strong></p>
<pre><code>Single split: Chỉ test trên 1 period
→ Nếu period đó đặc biệt (COVID, crash) → Kết quả không đại diện

Walk-forward: Test trên nhiều periods
→ Robust hơn, đánh giá thực tế hơn
</code></pre>
<p><strong>Expanding Window:</strong></p>
<pre><code>Fold 1: [████████] [test]
Fold 2: [██████████] [test]
Fold 3: [████████████] [test]
Fold 4: [██████████████] [test]

Train window tăng dần, dùng tất cả data quá khứ
</code></pre>
<p><strong>Rolling Window:</strong></p>
<pre><code>Fold 1: [████] [test]
Fold 2:   [████] [test]
Fold 3:     [████] [test]
Fold 4:       [████] [test]

Train window cố định, slide theo thời gian
</code></pre>
<p><strong>Code - Expanding Window:</strong></p>
<pre><code class="language-python">from sklearn.model_selection import TimeSeriesSplit

# TimeSeriesSplit = Expanding window
tscv = TimeSeriesSplit(n_splits=5)

scores = []
for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

    print(f&quot;Fold {fold+1}:&quot;)
    print(f&quot;  Train: {len(train_idx)} samples ({df.iloc[train_idx[0]]['date']} to {df.iloc[train_idx[-1]]['date']})&quot;)
    print(f&quot;  Test:  {len(test_idx)} samples ({df.iloc[test_idx[0]]['date']} to {df.iloc[test_idx[-1]]['date']})&quot;)

    model.fit(X_train, y_train)
    score = model.score(X_test, y_test)
    scores.append(score)

print(f&quot;\nAverage score: {np.mean(scores):.4f} ± {np.std(scores):.4f}&quot;)
</code></pre>
<p><strong>Code - Rolling Window:</strong></p>
<pre><code class="language-python">def rolling_window_cv(df, train_size=252, test_size=30, step=30):
    &quot;&quot;&quot;
    Rolling window cross-validation

    Args:
        train_size: 252 trading days = 1 năm
        test_size: 30 days = 1 tháng
        step: 30 days giữa các folds
    &quot;&quot;&quot;
    results = []
    start = 0

    while start + train_size + test_size &lt;= len(df):
        train = df.iloc[start:start + train_size]
        test = df.iloc[start + train_size:start + train_size + test_size]

        # Train and evaluate
        # ...

        start += step

    return results
</code></pre>
<h3 id="44-so-sanh-cac-strategies">4.4. So sánh các Strategies</h3>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>Ưu điểm</th>
<th>Nhược điểm</th>
<th>Khi nào dùng</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Simple Split</strong></td>
<td>Đơn giản</td>
<td>Không robust</td>
<td>Quick evaluation</td>
</tr>
<tr>
<td><strong>Expanding Window</strong></td>
<td>Dùng tất cả data</td>
<td>Train size tăng dần</td>
<td>Default choice</td>
</tr>
<tr>
<td><strong>Rolling Window</strong></td>
<td>Train size cố định</td>
<td>Bỏ data cũ</td>
<td>Regime changes</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="5-walk-forward-validation-research-grade">5. WALK-FORWARD VALIDATION (RESEARCH-GRADE)</h2>
<h3 id="51-tai-sao-can-walk-forward-validation">5.1. Tại sao cần Walk-Forward Validation?</h3>
<p><strong>Vấn đề với Single Split:</strong></p>
<pre><code>Data: 2015 ──────────────────────────── 2024
           [████████████ Train ████████████][Test]
                                          2023-2024

Chỉ test trên 1 period (2023-2024)
→ Nếu period đó đặc biệt (bull run / crash) → Kết quả không đại diện
→ Model có thể overfit vào period đó
→ KHÔNG BIẾT model hoạt động thế nào ở các thời điểm khác
</code></pre>
<p><strong>Walk-Forward giải quyết:</strong></p>
<pre><code>Fold 1: [████ Train ████][Val] 2015-2017 | 2018
Fold 2: [██████ Train ██████][Val] 2015-2018 | 2019
Fold 3: [████████ Train ████████][Val] 2015-2019 | 2020 (COVID!)
Fold 4: [██████████ Train ██████████][Val] 2015-2020 | 2021
Fold 5: [████████████ Train ████████████][Val] 2015-2021 | 2022

→ Test trên NHIỀU periods khác nhau
→ Đánh giá model trong nhiều market conditions
→ Kết quả robust và đáng tin cậy hơn
</code></pre>
<h3 id="52-expanding-window-validation">5.2. Expanding Window Validation</h3>
<p><strong>Định nghĩa:</strong> Train window tăng dần, sử dụng TẤT CẢ data quá khứ.</p>
<pre><code>Fold 1: [████████████████] [test]
Fold 2: [██████████████████] [test]
Fold 3: [████████████████████] [test]
Fold 4: [██████████████████████] [test]
Fold 5: [████████████████████████] [test]

→ Mỗi fold dùng nhiều data hơn fold trước
→ Giả định: Data cũ vẫn hữu ích
</code></pre>
<p><strong>Implementation đầy đủ:</strong></p>
<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error
from typing import List, Tuple, Dict, Any

class ExpandingWindowCV:
    &quot;&quot;&quot;
    Expanding Window Cross-Validation cho Time Series

    Đặc điểm:
    - Train size tăng dần qua mỗi fold
    - Test size cố định
    - Có thể có gap (embargo) giữa train và test
    &quot;&quot;&quot;

    def __init__(self, 
                 n_splits: int = 5,
                 test_size: int = 252,  # 1 năm trading
                 gap: int = 0,          # Embargo period
                 min_train_size: int = 504):  # Minimum 2 năm train
        &quot;&quot;&quot;
        Args:
            n_splits: Số folds
            test_size: Kích thước test set (số observations)
            gap: Khoảng cách giữa train và test (để tránh leakage)
            min_train_size: Kích thước tối thiểu của train set
        &quot;&quot;&quot;
        self.n_splits = n_splits
        self.test_size = test_size
        self.gap = gap
        self.min_train_size = min_train_size

    def split(self, X: pd.DataFrame) -&gt; List[Tuple[np.ndarray, np.ndarray]]:
        &quot;&quot;&quot;
        Generate train/test indices cho mỗi fold

        Returns:
            List of (train_indices, test_indices) tuples
        &quot;&quot;&quot;
        n_samples = len(X)

        # Tính kích thước cần thiết
        total_test_size = self.n_splits * self.test_size
        available_for_last_train = n_samples - self.test_size - self.gap

        if available_for_last_train &lt; self.min_train_size:
            raise ValueError(f&quot;Not enough data. Need at least {self.min_train_size + self.test_size + self.gap} samples&quot;)

        splits = []

        for fold in range(self.n_splits):
            # Test end position (từ cuối data ngược lại)
            test_end = n_samples - fold * self.test_size
            test_start = test_end - self.test_size

            # Train end (có gap)
            train_end = test_start - self.gap
            train_start = 0  # Expanding: luôn bắt đầu từ đầu

            if train_end - train_start &lt; self.min_train_size:
                continue

            train_indices = np.arange(train_start, train_end)
            test_indices = np.arange(test_start, test_end)

            splits.append((train_indices, test_indices))

        # Reverse để fold 1 là earliest
        return splits[::-1]

    def get_fold_info(self, X: pd.DataFrame, dates: pd.Series = None) -&gt; pd.DataFrame:
        &quot;&quot;&quot;
        Get detailed info về mỗi fold
        &quot;&quot;&quot;
        splits = self.split(X)
        info = []

        for fold, (train_idx, test_idx) in enumerate(splits, 1):
            fold_info = {
                'fold': fold,
                'train_size': len(train_idx),
                'test_size': len(test_idx),
                'train_start_idx': train_idx[0],
                'train_end_idx': train_idx[-1],
                'test_start_idx': test_idx[0],
                'test_end_idx': test_idx[-1],
            }

            if dates is not None:
                fold_info.update({
                    'train_start_date': dates.iloc[train_idx[0]],
                    'train_end_date': dates.iloc[train_idx[-1]],
                    'test_start_date': dates.iloc[test_idx[0]],
                    'test_end_date': dates.iloc[test_idx[-1]],
                })

            info.append(fold_info)

        return pd.DataFrame(info)


# Usage
cv = ExpandingWindowCV(n_splits=5, test_size=252, gap=5, min_train_size=504)

# Xem thông tin các folds
fold_info = cv.get_fold_info(X, df['date'])
print(fold_info.to_string(index=False))

# Cross-validation loop
results = []
for fold, (train_idx, test_idx) in enumerate(cv.split(X), 1):
    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

    # Train
    model.fit(X_train, y_train)

    # Predict
    y_pred = model.predict(X_test)

    # Metrics
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))

    results.append({
        'fold': fold,
        'train_size': len(train_idx),
        'test_size': len(test_idx),
        'MAE': mae,
        'RMSE': rmse
    })

    print(f&quot;Fold {fold}: MAE = {mae:.4f}, RMSE = {rmse:.4f}&quot;)

results_df = pd.DataFrame(results)
print(f&quot;\n=== SUMMARY ===&quot;)
print(f&quot;Mean MAE: {results_df['MAE'].mean():.4f} ± {results_df['MAE'].std():.4f}&quot;)
print(f&quot;Mean RMSE: {results_df['RMSE'].mean():.4f} ± {results_df['RMSE'].std():.4f}&quot;)
</code></pre>
<h3 id="53-rolling-window-validation-sliding-window">5.3. Rolling Window Validation (Sliding Window)</h3>
<p><strong>Định nghĩa:</strong> Train window CỐ ĐỊNH, slide theo thời gian.</p>
<pre><code>Fold 1: [████████] [test]
Fold 2:   [████████] [test]
Fold 3:     [████████] [test]
Fold 4:       [████████] [test]
Fold 5:         [████████] [test]

→ Train size luôn bằng nhau
→ Data cũ bị DROP
→ Phù hợp khi market dynamics thay đổi (regime changes)
</code></pre>
<p><strong>Khi nào dùng Rolling thay vì Expanding?</strong></p>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Nên dùng</th>
<th>Lý do</th>
</tr>
</thead>
<tbody>
<tr>
<td>Market ổn định</td>
<td>Expanding</td>
<td>Nhiều data = better</td>
</tr>
<tr>
<td>Regime changes</td>
<td>Rolling</td>
<td>Data cũ có thể misleading</td>
</tr>
<tr>
<td>Concept drift</td>
<td>Rolling</td>
<td>Model cần adapt</td>
</tr>
<tr>
<td>Research paper</td>
<td>Expanding</td>
<td>Standard trong academia</td>
</tr>
<tr>
<td>Trading system</td>
<td>Rolling</td>
<td>Practical, adaptive</td>
</tr>
</tbody>
</table>
<p><strong>Implementation:</strong></p>
<pre><code class="language-python">class RollingWindowCV:
    &quot;&quot;&quot;
    Rolling Window Cross-Validation cho Time Series

    Đặc điểm:
    - Train size CỐ ĐỊNH
    - Window slides theo thời gian
    - Data cũ bị drop
    &quot;&quot;&quot;

    def __init__(self,
                 n_splits: int = 5,
                 train_size: int = 504,   # 2 năm
                 test_size: int = 63,     # 3 tháng
                 step_size: int = 63,     # Step giữa các folds
                 gap: int = 0):           # Embargo
        self.n_splits = n_splits
        self.train_size = train_size
        self.test_size = test_size
        self.step_size = step_size
        self.gap = gap

    def split(self, X: pd.DataFrame) -&gt; List[Tuple[np.ndarray, np.ndarray]]:
        n_samples = len(X)
        splits = []

        for fold in range(self.n_splits):
            # Train start position
            train_start = fold * self.step_size
            train_end = train_start + self.train_size

            # Test positions (với gap)
            test_start = train_end + self.gap
            test_end = test_start + self.test_size

            if test_end &gt; n_samples:
                break

            train_indices = np.arange(train_start, train_end)
            test_indices = np.arange(test_start, test_end)

            splits.append((train_indices, test_indices))

        return splits


# Usage
cv = RollingWindowCV(
    n_splits=10,
    train_size=504,   # 2 năm
    test_size=63,     # 3 tháng
    step_size=63,     # Roll mỗi 3 tháng
    gap=5             # 5 ngày embargo
)

for fold, (train_idx, test_idx) in enumerate(cv.split(X), 1):
    print(f&quot;Fold {fold}: Train {len(train_idx)} samples, Test {len(test_idx)} samples&quot;)
</code></pre>
<h3 id="54-purged-cross-validation-chong-leakage">5.4. Purged Cross-Validation (Chống Leakage)</h3>
<p><strong>Vấn đề:</strong> Trong financial data, observation tại t có thể overlap với t+1, t+2, ...</p>
<pre><code>Ví dụ: 5-day return
Day 1: return[1:6]   = [d1, d2, d3, d4, d5]
Day 2: return[2:7]   = [d2, d3, d4, d5, d6]
Day 3: return[3:8]   = [d3, d4, d5, d6, d7]

→ Day 1 và Day 2 share d2, d3, d4, d5!
→ Nếu Day 1 trong train, Day 2 trong test → LEAKAGE!
</code></pre>
<p><strong>Purged CV: Loại bỏ overlap</strong></p>
<pre><code class="language-python">class PurgedKFoldCV:
    &quot;&quot;&quot;
    Purged K-Fold Cross-Validation

    Loại bỏ samples trong train set mà overlap với test set
    Thêm embargo period sau train để tránh leakage

    Reference: &quot;Advances in Financial Machine Learning&quot; - Marcos López de Prado
    &quot;&quot;&quot;

    def __init__(self,
                 n_splits: int = 5,
                 purge_gap: int = 5,     # Loại bỏ samples overlap
                 embargo_pct: float = 0.01):  # % data làm embargo
        self.n_splits = n_splits
        self.purge_gap = purge_gap
        self.embargo_pct = embargo_pct

    def split(self, X: pd.DataFrame, 
              t1: pd.Series = None) -&gt; List[Tuple[np.ndarray, np.ndarray]]:
        &quot;&quot;&quot;
        Args:
            X: Features DataFrame
            t1: Series với end time của mỗi observation
                Nếu None, assume no overlap
        &quot;&quot;&quot;
        n_samples = len(X)
        indices = np.arange(n_samples)

        # Tính embargo size
        embargo_size = int(n_samples * self.embargo_pct)

        # Chia thành n_splits theo thời gian
        test_size = n_samples // self.n_splits

        splits = []

        for fold in range(self.n_splits):
            test_start = fold * test_size
            test_end = min((fold + 1) * test_size, n_samples)

            test_indices = indices[test_start:test_end]

            # Train indices: tất cả trừ test + purge + embargo
            train_mask = np.ones(n_samples, dtype=bool)

            # Remove test
            train_mask[test_start:test_end] = False

            # Purge: Remove samples trước test có thể overlap
            purge_start = max(0, test_start - self.purge_gap)
            train_mask[purge_start:test_start] = False

            # Embargo: Remove samples ngay sau test
            embargo_end = min(n_samples, test_end + embargo_size)
            train_mask[test_end:embargo_end] = False

            # Chỉ lấy train TRƯỚC test (time series constraint)
            train_mask[test_end:] = False

            train_indices = indices[train_mask]

            if len(train_indices) &gt; 0:
                splits.append((train_indices, test_indices))

        return splits


# Usage với overlapping returns
cv = PurgedKFoldCV(n_splits=5, purge_gap=5, embargo_pct=0.01)

for fold, (train_idx, test_idx) in enumerate(cv.split(X), 1):
    print(f&quot;Fold {fold}:&quot;)
    print(f&quot;  Train: {len(train_idx)} samples [{train_idx[0]} to {train_idx[-1]}]&quot;)
    print(f&quot;  Test:  {len(test_idx)} samples [{test_idx[0]} to {test_idx[-1]}]&quot;)
    print(f&quot;  Gap between train and test: {test_idx[0] - train_idx[-1] - 1} samples&quot;)
</code></pre>
<h3 id="55-combinatorial-purged-cross-validation-cpcv">5.5. Combinatorial Purged Cross-Validation (CPCV)</h3>
<p><strong>Ý tưởng:</strong> Tạo nhiều train/test combinations hơn standard CV.</p>
<pre><code>Standard 5-fold: 5 combinations
CPCV với n=5, k=2: C(5,2) = 10 combinations

→ Nhiều evaluation points hơn
→ Giảm variance của performance estimate
</code></pre>
<pre><code class="language-python">from itertools import combinations

class CombinatorialPurgedCV:
    &quot;&quot;&quot;
    Combinatorial Purged Cross-Validation

    Tạo tất cả combinations có thể của test folds
    Mỗi combination có k folds làm test, n-k folds làm train

    Reference: López de Prado (2018)
    &quot;&quot;&quot;

    def __init__(self,
                 n_groups: int = 6,      # Số groups chia data
                 n_test_groups: int = 2,  # Số groups làm test mỗi lần
                 purge_gap: int = 5,
                 embargo_pct: float = 0.01):
        self.n_groups = n_groups
        self.n_test_groups = n_test_groups
        self.purge_gap = purge_gap
        self.embargo_pct = embargo_pct

    def split(self, X: pd.DataFrame) -&gt; List[Tuple[np.ndarray, np.ndarray]]:
        n_samples = len(X)
        indices = np.arange(n_samples)

        # Chia data thành n_groups
        group_size = n_samples // self.n_groups
        groups = []
        for i in range(self.n_groups):
            start = i * group_size
            end = (i + 1) * group_size if i &lt; self.n_groups - 1 else n_samples
            groups.append(indices[start:end])

        # Tạo tất cả combinations
        test_combinations = list(combinations(range(self.n_groups), self.n_test_groups))

        embargo_size = int(n_samples * self.embargo_pct)
        splits = []

        for test_group_indices in test_combinations:
            # Test indices
            test_indices = np.concatenate([groups[i] for i in test_group_indices])
            test_indices.sort()

            # Train mask
            train_mask = np.ones(n_samples, dtype=bool)

            # Remove test groups
            train_mask[test_indices] = False

            # Purge và embargo cho mỗi test group
            for group_idx in test_group_indices:
                group = groups[group_idx]
                test_start = group[0]
                test_end = group[-1]

                # Purge before
                purge_start = max(0, test_start - self.purge_gap)
                train_mask[purge_start:test_start] = False

                # Embargo after
                embargo_end = min(n_samples, test_end + embargo_size + 1)
                train_mask[test_end + 1:embargo_end] = False

            train_indices = indices[train_mask]

            # Chỉ giữ train TRƯỚC test (earliest test group)
            earliest_test = min(test_indices)
            train_indices = train_indices[train_indices &lt; earliest_test]

            if len(train_indices) &gt; 0:
                splits.append((train_indices, test_indices))

        return splits

# Usage
cv = CombinatorialPurgedCV(n_groups=6, n_test_groups=2)
n_splits = len(cv.split(X))
print(f&quot;Number of train/test combinations: {n_splits}&quot;)  # C(6,2) = 15
</code></pre>
<h3 id="56-aggregation-metrics-across-folds">5.6. Aggregation Metrics across Folds</h3>
<p><strong>Vấn đề:</strong> Làm sao tổng hợp kết quả từ nhiều folds?</p>
<pre><code class="language-python">def aggregate_cv_results(fold_results: List[Dict]) -&gt; Dict:
    &quot;&quot;&quot;
    Aggregate metrics từ multiple folds

    Args:
        fold_results: List of dicts với metrics per fold

    Returns:
        Dict với aggregated metrics
    &quot;&quot;&quot;
    df = pd.DataFrame(fold_results)

    metrics = ['MAE', 'RMSE', 'MAPE', 'DirectionalAccuracy']
    agg_results = {}

    for metric in metrics:
        if metric in df.columns:
            values = df[metric].dropna()

            agg_results[f'{metric}_mean'] = values.mean()
            agg_results[f'{metric}_std'] = values.std()
            agg_results[f'{metric}_min'] = values.min()
            agg_results[f'{metric}_max'] = values.max()
            agg_results[f'{metric}_median'] = values.median()

            # Confidence interval (95%)
            ci_lower = np.percentile(values, 2.5)
            ci_upper = np.percentile(values, 97.5)
            agg_results[f'{metric}_ci_95'] = (ci_lower, ci_upper)

    # Stability metrics
    if 'MAE' in df.columns:
        agg_results['stability_coefficient'] = df['MAE'].std() / df['MAE'].mean()
        agg_results['worst_fold_ratio'] = df['MAE'].max() / df['MAE'].min()

    return agg_results


def print_cv_summary(agg_results: Dict):
    &quot;&quot;&quot;Pretty print CV summary&quot;&quot;&quot;
    print(&quot;\n&quot; + &quot;=&quot;*60)
    print(&quot;WALK-FORWARD CROSS-VALIDATION SUMMARY&quot;)
    print(&quot;=&quot;*60)

    for metric in ['MAE', 'RMSE']:
        if f'{metric}_mean' in agg_results:
            mean = agg_results[f'{metric}_mean']
            std = agg_results[f'{metric}_std']
            ci = agg_results.get(f'{metric}_ci_95', (None, None))

            print(f&quot;\n{metric}:&quot;)
            print(f&quot;  Mean ± Std: {mean:.4f} ± {std:.4f}&quot;)
            print(f&quot;  Range: [{agg_results[f'{metric}_min']:.4f}, {agg_results[f'{metric}_max']:.4f}]&quot;)
            if ci[0]:
                print(f&quot;  95% CI: [{ci[0]:.4f}, {ci[1]:.4f}]&quot;)

    if 'stability_coefficient' in agg_results:
        print(f&quot;\nStability Metrics:&quot;)
        print(f&quot;  Coefficient of Variation: {agg_results['stability_coefficient']:.4f}&quot;)
        print(f&quot;  Worst/Best Fold Ratio: {agg_results['worst_fold_ratio']:.2f}&quot;)

        if agg_results['stability_coefficient'] &lt; 0.2:
            print(&quot;  → Model STABLE across folds&quot;)
        else:
            print(&quot;  → Model UNSTABLE - high variance across folds&quot;)

# Usage
agg = aggregate_cv_results(results)
print_cv_summary(agg)
</code></pre>
<h3 id="57-best-practices-cho-walk-forward-validation">5.7. Best Practices cho Walk-Forward Validation</h3>
<p><strong>1. Chọn test_size phù hợp:</strong></p>
<pre><code class="language-python"># Quarterly evaluation
test_size = 63  # ~3 tháng trading days

# Annual evaluation  
test_size = 252  # 1 năm

# Monthly evaluation (nhiều folds hơn)
test_size = 21  # 1 tháng
</code></pre>
<p><strong>2. Luôn dùng embargo/purge:</strong></p>
<pre><code class="language-python"># Minimum embargo = horizon của prediction
# Nếu predict 5-day return → embargo &gt;= 5

cv = ExpandingWindowCV(
    n_splits=5,
    test_size=252,
    gap=5  # Embargo 5 days
)
</code></pre>
<p><strong>3. Report đầy đủ metrics:</strong></p>
<pre><code class="language-python"># Không chỉ report mean, mà cả:
# - Standard deviation (stability)
# - Min/Max (worst/best case)
# - Confidence interval

print(f&quot;MAE: {mean:.4f} ± {std:.4f} [95% CI: {ci_lower:.4f}, {ci_upper:.4f}]&quot;)
</code></pre>
<p><strong>4. Visualize performance qua thời gian:</strong></p>
<pre><code class="language-python">import matplotlib.pyplot as plt

def plot_cv_performance(fold_results: List[Dict], dates: List):
    &quot;&quot;&quot;Visualize CV performance across folds&quot;&quot;&quot;
    fig, axes = plt.subplots(2, 1, figsize=(14, 8))

    folds = [r['fold'] for r in fold_results]
    maes = [r['MAE'] for r in fold_results]

    # MAE per fold
    axes[0].bar(folds, maes)
    axes[0].axhline(np.mean(maes), color='red', linestyle='--', label=f'Mean: {np.mean(maes):.4f}')
    axes[0].set_xlabel('Fold')
    axes[0].set_ylabel('MAE')
    axes[0].set_title('MAE across Walk-Forward Folds')
    axes[0].legend()

    # Cumulative performance
    cumulative_mae = np.cumsum(maes) / np.arange(1, len(maes) + 1)
    axes[1].plot(folds, cumulative_mae, marker='o')
    axes[1].set_xlabel('Fold')
    axes[1].set_ylabel('Cumulative MAE')
    axes[1].set_title('Cumulative Average MAE')

    plt.tight_layout()
    plt.show()
</code></pre>
<hr />
<h2 id="6-lookahead-bias">6. LOOKAHEAD BIAS</h2>
<h3 id="51-lookahead-bias-la-gi">5.1. Lookahead Bias là gì?</h3>
<p><strong>Định nghĩa:</strong> Model "nhìn thấy" thông tin từ tương lai trong quá trình training hoặc feature engineering.</p>
<p><strong>Hậu quả:</strong> Backtest performance tốt nhưng live trading thất bại hoàn toàn.</p>
<h3 id="52-cac-dang-lookahead-bias">5.2. Các dạng Lookahead Bias</h3>
<p><strong>1. Feature Engineering Leak:</strong></p>
<pre><code class="language-python"># SAI: Rolling mean với center=True
df['ma_20'] = df['close'].rolling(20, center=True).mean()
# center=True dùng 10 ngày trước VÀ 10 ngày sau!

# ĐÚNG: Chỉ dùng data quá khứ
df['ma_20'] = df['close'].rolling(20).mean().shift(1)
</code></pre>
<p><strong>2. Scaling/Normalization Leak:</strong></p>
<pre><code class="language-python"># SAI: Fit scaler trên toàn bộ data
scaler = StandardScaler()
df['close_scaled'] = scaler.fit_transform(df[['close']])
# mean, std tính từ cả test data!

# ĐÚNG: Chỉ fit trên train
scaler.fit(train[['close']])
train['close_scaled'] = scaler.transform(train[['close']])
test['close_scaled'] = scaler.transform(test[['close']])
</code></pre>
<p><strong>3. Target Encoding Leak:</strong></p>
<pre><code class="language-python"># SAI: Target encoding dùng toàn bộ data
sector_returns = df.groupby('sector')['return'].mean()
df['sector_encoded'] = df['sector'].map(sector_returns)
# Bao gồm returns từ tương lai!

# ĐÚNG: Chỉ dùng train data
sector_returns = train.groupby('sector')['return'].mean()
train['sector_encoded'] = train['sector'].map(sector_returns)
test['sector_encoded'] = test['sector'].map(sector_returns)
</code></pre>
<p><strong>4. Hyperparameter Tuning Leak:</strong></p>
<pre><code class="language-python"># SAI: Tune hyperparameters trên test set
for lr in [0.001, 0.01, 0.1]:
    model.fit(X_train, y_train)
    test_score = evaluate(X_test, y_test)  # Leak!
    if test_score &gt; best:
        best_lr = lr

# ĐÚNG: Dùng validation set
for lr in [0.001, 0.01, 0.1]:
    model.fit(X_train, y_train)
    val_score = evaluate(X_val, y_val)  # Val, không phải Test
    if val_score &gt; best:
        best_lr = lr

# Test chỉ dùng 1 lần cuối cùng
final_score = evaluate(X_test, y_test)
</code></pre>
<p><strong>5. Point-in-Time Data:</strong></p>
<pre><code class="language-python"># SAI: Dùng financial data không point-in-time
# Ví dụ: EPS Q1/2023 công bố tháng 4/2023
# Nhưng dùng cho prediction tháng 1/2023!

# ĐÚNG: Chỉ dùng data đã available tại thời điểm đó
# EPS Q4/2022 (công bố tháng 1/2023) cho prediction tháng 2/2023
</code></pre>
<h3 id="53-checklist-tranh-lookahead-bias">5.3. Checklist tránh Lookahead Bias</h3>
<pre><code>□ Không dùng center=True trong rolling
□ Shift tất cả features ít nhất 1 period
□ Fit scaler/encoder chỉ trên train
□ Không tune hyperparameters trên test
□ Point-in-time data cho fundamentals
□ Split data theo thời gian, không random
□ Validation set riêng với test set
</code></pre>
<h3 id="54-test-e-phat-hien-lookahead">5.4. Test để phát hiện Lookahead</h3>
<pre><code class="language-python">def check_for_lookahead(df, feature_col, target_col):
    &quot;&quot;&quot;
    Kiểm tra xem feature có lookahead không

    Nếu correlation quá cao (&gt;0.9) → Có thể có lookahead!
    &quot;&quot;&quot;
    corr = df[feature_col].corr(df[target_col])

    if abs(corr) &gt; 0.9:
        print(f&quot;WARNING: {feature_col} has correlation {corr:.3f} with target&quot;)
        print(&quot;This may indicate lookahead bias!&quot;)

    return corr

# Test
for col in feature_columns:
    check_for_lookahead(df, col, 'return_1d')
</code></pre>
<hr />
<h2 id="7-stationarity">7. STATIONARITY</h2>
<h3 id="61-stationarity-la-gi">6.1. Stationarity là gì?</h3>
<p><strong>Định nghĩa:</strong> Tính chất thống kê không đổi theo thời gian.</p>
<p><strong>Stationary series có:</strong>
- Mean (trung bình) không đổi
- Variance (phương sai) không đổi
- Autocovariance chỉ phụ thuộc lag, không phụ thuộc thời điểm</p>
<h3 id="62-tai-sao-stationarity-quan-trong">6.2. Tại sao Stationarity quan trọng?</h3>
<p><strong>Về mặt toán học:</strong></p>
<pre><code>Model ARIMA giả định: E[y(t)] = μ (constant)

Nếu non-stationary:
- E[y(t)] = f(t) (thay đổi theo t)
- Model parameters không ổn định
- Predictions không reliable

Ví dụ:
- Train: 2015-2020, mean price = 50
- Test: 2021-2023, mean price = 100
- Model trained với mean=50 sẽ sai hoàn toàn!
</code></pre>
<p><strong>Về mặt thực tế:</strong></p>
<pre><code>Non-stationary (Price):
2015: Mean = 30K
2020: Mean = 70K
2024: Mean = 100K
→ Không thể dùng past patterns để predict future

Stationary (Returns):
2015: Mean ≈ 0.1%
2020: Mean ≈ 0.08%
2024: Mean ≈ 0.12%
→ Past patterns có thể giúp predict future
</code></pre>
<h3 id="63-kiem-tra-stationarity">6.3. Kiểm tra Stationarity</h3>
<p><strong>Visual Test:</strong></p>
<pre><code class="language-python">import matplotlib.pyplot as plt

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Price (non-stationary)
axes[0, 0].plot(df['close'])
axes[0, 0].set_title('Price (Non-Stationary)')

# Returns (stationary)
axes[0, 1].plot(df['return'])
axes[0, 1].set_title('Returns (Stationary)')

# Rolling statistics for price
rolling_mean = df['close'].rolling(252).mean()
rolling_std = df['close'].rolling(252).std()
axes[1, 0].plot(df['close'], label='Price')
axes[1, 0].plot(rolling_mean, label='Rolling Mean')
axes[1, 0].legend()
axes[1, 0].set_title('Price with Rolling Mean (increasing)')

# Rolling statistics for returns
rolling_mean_ret = df['return'].rolling(252).mean()
rolling_std_ret = df['return'].rolling(252).std()
axes[1, 1].plot(rolling_mean_ret, label='Rolling Mean')
axes[1, 1].plot(rolling_std_ret, label='Rolling Std')
axes[1, 1].legend()
axes[1, 1].set_title('Returns Rolling Stats (stable)')

plt.tight_layout()
plt.show()
</code></pre>
<p><strong>ADF Test (Augmented Dickey-Fuller):</strong></p>
<pre><code class="language-python">from statsmodels.tsa.stattools import adfuller

def check_stationarity(series, name=''):
    &quot;&quot;&quot;
    ADF Test:
    H0: Series is non-stationary (has unit root)
    H1: Series is stationary

    p-value &lt; 0.05 → Reject H0 → Stationary
    p-value &gt; 0.05 → Accept H0 → Non-stationary
    &quot;&quot;&quot;
    result = adfuller(series.dropna())

    print(f&quot;=== {name} ===&quot;)
    print(f&quot;ADF Statistic: {result[0]:.4f}&quot;)
    print(f&quot;p-value: {result[1]:.4f}&quot;)
    print(f&quot;Critical Values:&quot;)
    for key, value in result[4].items():
        print(f&quot;  {key}: {value:.4f}&quot;)

    if result[1] &lt; 0.05:
        print(&quot;→ STATIONARY (p &lt; 0.05)&quot;)
    else:
        print(&quot;→ NON-STATIONARY (p &gt; 0.05)&quot;)

    return result[1] &lt; 0.05

# Test
check_stationarity(df['close'], 'Price')
check_stationarity(df['return'], 'Returns')
</code></pre>
<p><strong>KPSS Test (alternative):</strong></p>
<pre><code class="language-python">from statsmodels.tsa.stattools import kpss

def kpss_test(series, name=''):
    &quot;&quot;&quot;
    KPSS Test:
    H0: Series is stationary
    H1: Series is non-stationary

    p-value &lt; 0.05 → Reject H0 → Non-stationary
    p-value &gt; 0.05 → Accept H0 → Stationary

    (Ngược với ADF!)
    &quot;&quot;&quot;
    result = kpss(series.dropna())

    print(f&quot;=== {name} ===&quot;)
    print(f&quot;KPSS Statistic: {result[0]:.4f}&quot;)
    print(f&quot;p-value: {result[1]:.4f}&quot;)

    if result[1] &lt; 0.05:
        print(&quot;→ NON-STATIONARY&quot;)
    else:
        print(&quot;→ STATIONARY&quot;)
</code></pre>
<hr />
<h2 id="8-differencing-va-transformations">8. DIFFERENCING VÀ TRANSFORMATIONS</h2>
<h3 id="71-first-differencing">7.1. First Differencing</h3>
<p><strong>Ý tưởng:</strong> Chuyển từ levels sang changes.</p>
<pre><code>y'(t) = y(t) - y(t-1)

Price:   [100, 102, 105, 103, 108]
Diff:    [NaN,  2,   3,  -2,   5]
</code></pre>
<p><strong>Code:</strong></p>
<pre><code class="language-python"># First difference
df['close_diff'] = df['close'].diff()

# Check stationarity after differencing
check_stationarity(df['close_diff'], 'Price after 1st diff')
</code></pre>
<p><strong>Khi nào cần:</strong>
- Price levels (almost always need differencing)
- Series có trend</p>
<h3 id="72-second-differencing">7.2. Second Differencing</h3>
<p><strong>Khi first differencing không đủ:</strong></p>
<pre><code>y''(t) = y'(t) - y'(t-1)
       = [y(t) - y(t-1)] - [y(t-1) - y(t-2)]
       = y(t) - 2*y(t-1) + y(t-2)
</code></pre>
<pre><code class="language-python"># Second difference
df['close_diff2'] = df['close'].diff().diff()

# Thường không cần diff 2 lần cho stock prices
# Returns (first diff of log prices) thường đã stationary
</code></pre>
<h3 id="73-log-transform">7.3. Log Transform</h3>
<p><strong>Tại sao dùng Log?</strong></p>
<pre><code>1. Giảm heteroskedasticity (variance thay đổi theo level)
2. Chuyển multiplicative relationships → additive
3. Log returns có interpretation tốt hơn

Price 100 → 110: +10% 
Price 1000 → 1100: +10%

Với log:
log(110) - log(100) ≈ 0.095
log(1100) - log(1000) ≈ 0.095
→ Comparable!
</code></pre>
<pre><code class="language-python">import numpy as np

# Log transform
df['log_price'] = np.log(df['close'])

# Log returns (preferred in finance)
df['log_return'] = np.log(df['close'] / df['close'].shift(1))
# Equivalent to: np.log(df['close']).diff()
</code></pre>
<h3 id="74-cac-transformations-khac">7.4. Các Transformations khác</h3>
<p><strong>Box-Cox Transform:</strong></p>
<pre><code class="language-python">from scipy.stats import boxcox

# Tự động tìm lambda tối ưu
df['close_boxcox'], lambda_param = boxcox(df['close'])
print(f&quot;Optimal lambda: {lambda_param:.4f}&quot;)
</code></pre>
<p><strong>Seasonal Differencing:</strong></p>
<pre><code class="language-python"># Remove yearly seasonality (252 trading days)
df['close_seasonal_diff'] = df['close'] - df['close'].shift(252)
</code></pre>
<h3 id="75-workflow-e-at-stationarity">7.5. Workflow để đạt Stationarity</h3>
<pre><code class="language-python">def make_stationary(series, max_diff=2):
    &quot;&quot;&quot;
    Tự động differencing cho đến khi stationary
    &quot;&quot;&quot;
    d = 0
    current = series.copy()

    while d &lt; max_diff:
        result = adfuller(current.dropna())
        if result[1] &lt; 0.05:
            print(f&quot;Stationary after {d} differencing(s)&quot;)
            return current, d

        current = current.diff()
        d += 1

    print(f&quot;Warning: Not stationary after {max_diff} differencing(s)&quot;)
    return current, d

# Usage
stationary_series, d = make_stationary(df['close'])
print(f&quot;d = {d} for ARIMA(p, {d}, q)&quot;)
</code></pre>
<hr />
<h2 id="9-mean-reversion-vs-momentum">9. MEAN-REVERSION VS MOMENTUM</h2>
<h3 id="81-mean-reversion">8.1. Mean-Reversion</h3>
<p><strong>Định nghĩa:</strong> Giá có xu hướng quay về mean sau khi di chuyển xa.</p>
<pre><code>Price
  │
  │     ╱╲
  │    ╱  ╲    ╱╲
  │───╱────╲──╱──╲───── Mean
  │          ╲╱
  │
  └────────────────────→ Time

Giá cao hơn mean → Sẽ giảm
Giá thấp hơn mean → Sẽ tăng
</code></pre>
<p><strong>Đặc điểm:</strong>
- Negative autocorrelation
- Half-life: Thời gian để giá quay về mean
- Bollinger Bands, RSI overbought/oversold</p>
<p><strong>Trading Strategy:</strong></p>
<pre><code class="language-python"># Mean-reversion strategy
df['z_score'] = (df['close'] - df['close'].rolling(20).mean()) / df['close'].rolling(20).std()

df['signal'] = 0
df.loc[df['z_score'] &gt; 2, 'signal'] = -1   # Sell when too high
df.loc[df['z_score'] &lt; -2, 'signal'] = 1   # Buy when too low
</code></pre>
<h3 id="82-momentum">8.2. Momentum</h3>
<p><strong>Định nghĩa:</strong> Giá có xu hướng tiếp tục theo hướng đang di chuyển.</p>
<pre><code>Price
  │
  │            ╱╱
  │          ╱╱
  │        ╱╱
  │      ╱╱
  │    ╱╱
  │  ╱╱
  └────────────────────→ Time

Giá đang tăng → Tiếp tục tăng
Giá đang giảm → Tiếp tục giảm
</code></pre>
<p><strong>Đặc điểm:</strong>
- Positive autocorrelation
- Trend-following
- Moving average crossover, breakout</p>
<p><strong>Trading Strategy:</strong></p>
<pre><code class="language-python"># Momentum strategy
df['momentum_20'] = df['close'] / df['close'].shift(20) - 1

df['signal'] = 0
df.loc[df['momentum_20'] &gt; 0.05, 'signal'] = 1   # Buy when momentum up
df.loc[df['momentum_20'] &lt; -0.05, 'signal'] = -1  # Sell when momentum down
</code></pre>
<h3 id="83-regime-detection">8.3. Regime Detection</h3>
<p><strong>Thực tế:</strong> Market thay đổi giữa các regimes.</p>
<pre><code>2019-2020: Mean-reversion regime (range-bound)
2020-2021: Momentum regime (strong bull)
2022: Mean-reversion regime (consolidation)
2023: Momentum regime (recovery)
</code></pre>
<p><strong>Code để detect regime:</strong></p>
<pre><code class="language-python">def detect_regime(returns, window=60):
    &quot;&quot;&quot;
    Detect market regime based on autocorrelation

    Positive autocorr → Momentum regime
    Negative autocorr → Mean-reversion regime
    &quot;&quot;&quot;
    # Rolling autocorrelation lag-1
    def rolling_autocorr(x):
        return x.autocorr(lag=1)

    autocorr = returns.rolling(window).apply(rolling_autocorr)

    regime = pd.Series(index=returns.index, dtype='object')
    regime[autocorr &gt; 0.1] = 'Momentum'
    regime[autocorr &lt; -0.1] = 'Mean-Reversion'
    regime[(autocorr &gt;= -0.1) &amp; (autocorr &lt;= 0.1)] = 'Random'

    return regime, autocorr

regime, autocorr = detect_regime(df['return'])
print(regime.value_counts())
</code></pre>
<h3 id="84-so-sanh-strategies">8.4. So sánh Strategies</h3>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Mean-Reversion</th>
<th>Momentum</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Autocorrelation</strong></td>
<td>Negative</td>
<td>Positive</td>
</tr>
<tr>
<td><strong>Strategy</strong></td>
<td>Buy low, sell high</td>
<td>Buy winners, sell losers</td>
</tr>
<tr>
<td><strong>Indicators</strong></td>
<td>RSI, Bollinger</td>
<td>MA crossover, Breakout</td>
</tr>
<tr>
<td><strong>Time horizon</strong></td>
<td>Short-term</td>
<td>Medium to long-term</td>
</tr>
<tr>
<td><strong>Risk</strong></td>
<td>Gap risk, trend</td>
<td>Reversal risk</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="10-forecasting-metrics">10. FORECASTING METRICS</h2>
<h3 id="91-mae-mean-absolute-error">9.1. MAE (Mean Absolute Error)</h3>
<p><strong>Công thức:</strong></p>
<pre><code>MAE = (1/n) × Σ|y_true - y_pred|
</code></pre>
<p><strong>Ví dụ:</strong></p>
<pre><code>y_true = [100, 105, 102]
y_pred = [98,  107, 100]
error  = [2,   2,   2]
MAE = (2 + 2 + 2) / 3 = 2
</code></pre>
<p><strong>Đặc điểm:</strong>
- Đơn vị giống với y
- Không phạt nặng outliers
- Dễ interpret: "Trung bình sai 2 đơn vị"</p>
<pre><code class="language-python">from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(y_true, y_pred)
print(f&quot;MAE: {mae:.2f}&quot;)
</code></pre>
<h3 id="92-rmse-root-mean-squared-error">9.2. RMSE (Root Mean Squared Error)</h3>
<p><strong>Công thức:</strong></p>
<pre><code>RMSE = √[(1/n) × Σ(y_true - y_pred)²]
</code></pre>
<p><strong>Ví dụ:</strong></p>
<pre><code>y_true = [100, 105, 102]
y_pred = [98,  107, 100]
error² = [4,   4,   4]
MSE = (4 + 4 + 4) / 3 = 4
RMSE = √4 = 2
</code></pre>
<p><strong>Đặc điểm:</strong>
- Đơn vị giống với y
- Phạt nặng outliers (vì bình phương)
- Sensitive to large errors</p>
<pre><code class="language-python">from sklearn.metrics import mean_squared_error
import numpy as np

rmse = np.sqrt(mean_squared_error(y_true, y_pred))
print(f&quot;RMSE: {rmse:.2f}&quot;)
</code></pre>
<h3 id="93-mape-mean-absolute-percentage-error">9.3. MAPE (Mean Absolute Percentage Error)</h3>
<p><strong>Công thức:</strong></p>
<pre><code>MAPE = (1/n) × Σ|((y_true - y_pred) / y_true)| × 100%
</code></pre>
<p><strong>Ví dụ:</strong></p>
<pre><code>y_true = [100, 105, 102]
y_pred = [98,  107, 100]
error% = [2%,  1.9%, 2%]
MAPE = (2 + 1.9 + 2) / 3 = 1.97%
</code></pre>
<p><strong>Đặc điểm:</strong>
- Scale-independent (%)
- Dễ so sánh giữa các series khác nhau
- Vấn đề: Undefined khi y_true = 0</p>
<pre><code class="language-python">def mape(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

print(f&quot;MAPE: {mape(y_true, y_pred):.2f}%&quot;)
</code></pre>
<h3 id="94-so-sanh-metrics">9.4. So sánh Metrics</h3>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Ưu điểm</th>
<th>Nhược điểm</th>
<th>Khi nào dùng</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MAE</strong></td>
<td>Robust to outliers, dễ hiểu</td>
<td>Không phạt nặng lỗi lớn</td>
<td>Default choice</td>
</tr>
<tr>
<td><strong>RMSE</strong></td>
<td>Phạt lỗi lớn</td>
<td>Sensitive to outliers</td>
<td>Khi lỗi lớn quan trọng</td>
</tr>
<tr>
<td><strong>MAPE</strong></td>
<td>Scale-free</td>
<td>Undefined when y=0, asymmetric</td>
<td>So sánh nhiều series</td>
</tr>
</tbody>
</table>
<h3 id="95-metrics-cho-trading">9.5. Metrics cho Trading</h3>
<p><strong>Ngoài accuracy, cần xét:</strong></p>
<pre><code class="language-python"># Directional Accuracy
correct_direction = np.sign(y_true[1:] - y_true[:-1]) == np.sign(y_pred[1:] - y_pred[:-1])
directional_accuracy = correct_direction.mean()
print(f&quot;Directional Accuracy: {directional_accuracy:.2%}&quot;)

# Sharpe Ratio của strategy
returns = calculate_returns(y_pred)
sharpe = returns.mean() / returns.std() * np.sqrt(252)
print(f&quot;Sharpe Ratio: {sharpe:.2f}&quot;)
</code></pre>
<hr />
<h2 id="11-multi-step-forecasting">11. MULTI-STEP FORECASTING</h2>
<h3 id="101-one-step-vs-multi-step">10.1. One-Step vs Multi-Step</h3>
<p><strong>One-Step Forecast:</strong></p>
<pre><code>Input:  [t-10, t-9, ..., t-1, t]
Output: t+1

Dự đoán: Ngày mai duy nhất
</code></pre>
<p><strong>Multi-Step Forecast:</strong></p>
<pre><code>Input:  [t-10, t-9, ..., t-1, t]
Output: [t+1, t+2, t+3, t+4, t+5]

Dự đoán: 5 ngày tiếp theo
</code></pre>
<h3 id="102-recursive-strategy">10.2. Recursive Strategy</h3>
<p><strong>Ý tưởng:</strong> Train 1 model, dùng predictions làm input cho step tiếp theo.</p>
<pre><code>Step 1: f([t-10,...,t]) → ŷ(t+1)
Step 2: f([t-9,...,t, ŷ(t+1)]) → ŷ(t+2)
Step 3: f([t-8,...,ŷ(t+1), ŷ(t+2)]) → ŷ(t+3)
...
</code></pre>
<p><strong>Code:</strong></p>
<pre><code class="language-python">def recursive_forecast(model, X_last, steps=5):
    &quot;&quot;&quot;
    Recursive multi-step forecasting

    Args:
        model: Trained model
        X_last: Last known feature vector
        steps: Number of steps to forecast
    &quot;&quot;&quot;
    forecasts = []
    X_current = X_last.copy()

    for step in range(steps):
        # Predict next step
        y_pred = model.predict(X_current.reshape(1, -1))[0]
        forecasts.append(y_pred)

        # Shift features and add prediction
        X_current = np.roll(X_current, -1)
        X_current[-1] = y_pred

    return forecasts

# Usage
last_features = X_test.iloc[-1].values
forecasts = recursive_forecast(model, last_features, steps=5)
</code></pre>
<p><strong>Ưu điểm:</strong>
- Chỉ cần train 1 model
- Có thể forecast arbitrary horizon</p>
<p><strong>Nhược điểm:</strong>
- Error accumulation (lỗi tích lũy)
- Horizon càng xa, error càng lớn</p>
<h3 id="103-direct-strategy">10.3. Direct Strategy</h3>
<p><strong>Ý tưởng:</strong> Train model riêng cho mỗi horizon.</p>
<pre><code>Model 1: f₁([t-10,...,t]) → ŷ(t+1)
Model 2: f₂([t-10,...,t]) → ŷ(t+2)
Model 3: f₃([t-10,...,t]) → ŷ(t+3)
...
</code></pre>
<p><strong>Code:</strong></p>
<pre><code class="language-python">def direct_forecast(X_train, y_series, X_test, max_horizon=5):
    &quot;&quot;&quot;
    Direct multi-step forecasting

    Train separate model for each horizon
    &quot;&quot;&quot;
    from sklearn.linear_model import Ridge

    models = {}
    forecasts = {}

    for h in range(1, max_horizon + 1):
        # Create target for horizon h
        y_h = y_series.shift(-h)

        # Align and remove NaN
        valid_idx = ~y_h.isna()
        X_train_h = X_train[valid_idx]
        y_train_h = y_h[valid_idx]

        # Train model for horizon h
        model = Ridge()
        model.fit(X_train_h, y_train_h)
        models[h] = model

        # Forecast
        forecasts[h] = model.predict(X_test)[-1]

        print(f&quot;Horizon {h}: Forecast = {forecasts[h]:.2f}&quot;)

    return models, forecasts

models, forecasts = direct_forecast(X_train, df['close'], X_test, max_horizon=5)
</code></pre>
<p><strong>Ưu điểm:</strong>
- Mỗi horizon được optimize riêng
- Không có error accumulation</p>
<p><strong>Nhược điểm:</strong>
- Cần train nhiều models
- Không leverage relationships giữa các horizons</p>
<h3 id="104-multi-output-strategy">10.4. Multi-Output Strategy</h3>
<p><strong>Ý tưởng:</strong> Train 1 model với multiple outputs.</p>
<pre><code>Model: f([t-10,...,t]) → [ŷ(t+1), ŷ(t+2), ŷ(t+3), ŷ(t+4), ŷ(t+5)]
</code></pre>
<p><strong>Code với Neural Network:</strong></p>
<pre><code class="language-python">import torch
import torch.nn as nn

class MultiStepModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, n_steps):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, n_steps)  # Multi-output
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)  # Output: [batch, n_steps]
        return x

# Training
model = MultiStepModel(input_dim=10, hidden_dim=64, n_steps=5)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters())

# y_train shape: [batch, 5] - 5 days forecast
</code></pre>
<h3 id="105-so-sanh-strategies">10.5. So sánh Strategies</h3>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>Số models</th>
<th>Error accumulation</th>
<th>Complexity</th>
<th>Khi nào dùng</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Recursive</strong></td>
<td>1</td>
<td>Có</td>
<td>Thấp</td>
<td>Prototype, short horizon</td>
</tr>
<tr>
<td><strong>Direct</strong></td>
<td>H models</td>
<td>Không</td>
<td>Trung bình</td>
<td>Production, accuracy matters</td>
</tr>
<tr>
<td><strong>Multi-Output</strong></td>
<td>1</td>
<td>Không</td>
<td>Cao</td>
<td>Deep learning, nhiều data</td>
</tr>
</tbody>
</table>
<h3 id="106-best-practices">10.6. Best Practices</h3>
<pre><code class="language-python"># 1. Start với Recursive (simple baseline)
recursive_forecasts = recursive_forecast(model, X_last, steps=5)

# 2. Compare với Direct
direct_forecasts = direct_forecast(X_train, y, X_test, max_horizon=5)

# 3. Evaluate per horizon
for h in range(1, 6):
    print(f&quot;Horizon {h}:&quot;)
    print(f&quot;  Recursive MAE: {mae(y_true[h], recursive_forecasts[h-1]):.4f}&quot;)
    print(f&quot;  Direct MAE: {mae(y_true[h], direct_forecasts[h]):.4f}&quot;)

# 4. Use Direct for production if accuracy &gt; speed
</code></pre>
<hr />
<h2 id="12-bai-tap-thuc-hanh">12. BÀI TẬP THỰC HÀNH</h2>
<h3 id="bai-tap-1-phan-tich-autocorrelation">Bài tập 1: Phân tích Autocorrelation</h3>
<p><strong>Yêu cầu:</strong>
1. Load data FPT
2. Tính returns
3. Vẽ ACF và PACF
4. Xác định: Market có momentum hay mean-reversion?</p>
<pre><code class="language-python"># Gợi ý
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# Load data
df = pd.read_csv('data/features/vn30/FPT.csv')
df['return'] = df['close'].pct_change()

# Plot ACF và PACF
fig, axes = plt.subplots(2, 1, figsize=(12, 8))
plot_acf(df['return'].dropna(), lags=20, ax=axes[0])
plot_pacf(df['return'].dropna(), lags=20, ax=axes[1])
plt.show()

# Phân tích và kết luận
</code></pre>
<h3 id="bai-tap-2-kiem-tra-stationarity">Bài tập 2: Kiểm tra Stationarity</h3>
<p><strong>Yêu cầu:</strong>
1. Test stationarity cho Price và Returns
2. Nếu non-stationary, transform để đạt stationarity
3. Xác định d cho ARIMA</p>
<pre><code class="language-python"># Gợi ý
from statsmodels.tsa.stattools import adfuller

# Test price
result_price = adfuller(df['close'].dropna())
print(f&quot;Price p-value: {result_price[1]:.4f}&quot;)

# Test returns
result_returns = adfuller(df['return'].dropna())
print(f&quot;Returns p-value: {result_returns[1]:.4f}&quot;)

# Kết luận d = ?
</code></pre>
<h3 id="bai-tap-3-walk-forward-validation">Bài tập 3: Walk-Forward Validation</h3>
<p><strong>Yêu cầu:</strong>
1. Implement expanding window với 5 folds
2. Train Linear Regression trên mỗi fold
3. Tính average MAE và std</p>
<pre><code class="language-python"># Gợi ý
from sklearn.model_selection import TimeSeriesSplit
from sklearn.linear_model import LinearRegression

tscv = TimeSeriesSplit(n_splits=5)
mae_scores = []

for train_idx, test_idx in tscv.split(X):
    # Train and evaluate
    # TODO: Implement
    pass

print(f&quot;Average MAE: {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}&quot;)
</code></pre>
<h3 id="bai-tap-4-multi-step-forecasting">Bài tập 4: Multi-Step Forecasting</h3>
<p><strong>Yêu cầu:</strong>
1. Implement Recursive forecasting (5 days)
2. Implement Direct forecasting (5 days)
3. So sánh MAE per horizon</p>
<pre><code class="language-python"># Gợi ý
# Recursive
recursive_preds = recursive_forecast(model, X_last, steps=5)

# Direct
for h in range(1, 6):
    y_h = df['close'].shift(-h)
    # Train model_h
    # Predict

# Compare
</code></pre>
<h3 id="bai-tap-5-lookahead-bias-detection">Bài tập 5: Lookahead Bias Detection</h3>
<p><strong>Yêu cầu:</strong>
1. Tạo feature có lookahead bias (có ý)
2. Kiểm tra correlation bất thường
3. Fix lookahead bias</p>
<pre><code class="language-python"># Gợi ý
# SAI
df['ma_20_wrong'] = df['close'].rolling(20, center=True).mean()

# ĐÚNG  
df['ma_20_correct'] = df['close'].rolling(20).mean().shift(1)

# So sánh correlation với target
</code></pre>
<hr />
<h2 id="kiem-tra-hieu-bai">Kiểm tra hiểu bài</h2>
<p><strong>Phần Autocorrelation:</strong>
- [ ] Giải thích được ACF vs PACF
- [ ] Đọc được ACF/PACF để chọn AR/MA
- [ ] Hiểu ý nghĩa của autocorrelation trong trading</p>
<p><strong>Phần Features:</strong>
- [ ] Phân biệt được lag vs rolling features
- [ ] Biết khi nào dùng loại nào</p>
<p><strong>Phần Validation:</strong>
- [ ] Implement được walk-forward validation
- [ ] Hiểu tại sao không được random split</p>
<p><strong>Phần Lookahead:</strong>
- [ ] Liệt kê được các dạng lookahead bias
- [ ] Biết cách phát hiện và tránh</p>
<p><strong>Phần Stationarity:</strong>
- [ ] Giải thích được tại sao stationarity quan trọng
- [ ] Kiểm tra và transform được non-stationary series</p>
<p><strong>Phần Regimes:</strong>
- [ ] Phân biệt được mean-reversion vs momentum
- [ ] Hiểu regime changes</p>
<p><strong>Phần Metrics:</strong>
- [ ] Tính được MAE, RMSE, MAPE
- [ ] Biết khi nào dùng metric nào</p>
<p><strong>Phần Multi-Step:</strong>
- [ ] Implement được recursive và direct strategies
- [ ] So sánh và chọn strategy phù hợp</p>
<hr />
<h2 id="tai-lieu-tham-khao">Tài liệu tham khảo</h2>
<p><strong>Books:</strong>
- "Forecasting: Principles and Practice" (3rd ed) - Rob Hyndman &amp; George Athanasopoulos (FREE: https://otexts.com/fpp3/)
- "Time Series Analysis and Its Applications" - Shumway &amp; Stoffer</p>
<p><strong>Python Libraries:</strong>
- <code>statsmodels</code>: ARIMA, ACF/PACF, ADF test
- <code>pmdarima</code>: Auto ARIMA
- <code>sktime</code>: Sklearn-compatible time series</p>
<hr />
<h2 id="buoc-tiep-theo">Bước tiếp theo</h2>
<p>Sau khi hoàn thành bài này, sang:
- <code>02_modeling/01_BASELINE_MODELS.md</code> - ARIMA, GARCH
- <code>02_modeling/02_ML_MODELS.md</code> - XGBoost, LightGBM
- <code>02_modeling/03_LSTM_GRU.md</code> - Deep Learning cho Time Series</p>
  </main>
</body>
</html>
