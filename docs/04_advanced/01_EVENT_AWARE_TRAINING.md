# ğŸ¯ EVENT-AWARE TRAINING
## ÄÃ¡nh trá»ng sá»‘ cao cho shock events - Pain Point #1

---

## ğŸ“š Má»¤C Lá»¤C

1. [Váº¥n Ä‘á» vá»›i Training thÃ´ng thÆ°á»ng](#1-váº¥n-Ä‘á»-vá»›i-training-thÃ´ng-thÆ°á»ng)
2. [Event-Aware Training lÃ  gÃ¬?](#2-event-aware-training-lÃ -gÃ¬)
3. [PhÃ¡t hiá»‡n Event Days](#3-phÃ¡t-hiá»‡n-event-days)
4. [Weighted Loss Functions](#4-weighted-loss-functions)
5. [Event-Aware Metrics](#5-event-aware-metrics)
6. [Implementation Guide](#6-implementation-guide)
7. [BÃ i táº­p thá»±c hÃ nh](#7-bÃ i-táº­p-thá»±c-hÃ nh)

---

## 1. Váº¤N Äá»€ Vá»šI TRAINING THÃ”NG THÆ¯á»œNG

### ğŸ¤” Váº¥n Ä‘á»

**Training thÃ´ng thÆ°á»ng:**
```
Loss = MSE(y_pred, y_true)
     = (1/n) Ã— Î£(y_pred - y_true)Â²

â†’ Má»i ngÃ y Ä‘á»u Ä‘Æ°á»£c Ä‘á»‘i xá»­ BÃŒNH Äáº²NG
```

**Háº­u quáº£:**
```
Normal days (95%):  Error = 1%  â†’ Loss = 0.01
Event days (5%):    Error = 10% â†’ Loss = 1.00

Average Loss = 0.95 Ã— 0.01 + 0.05 Ã— 1.00 = 0.0595

â†’ Model optimize cho normal days
â†’ Bá» qua event days (vÃ¬ chá»‰ chiáº¿m 5%)
â†’ Dá»± Ä‘oÃ¡n KÃ‰M khi cÃ³ shock!
```

### ğŸ“Š VÃ­ dá»¥ thá»±c táº¿

**COVID Crash (Feb-Mar 2020):**
```
Normal days:
- Model dá»± Ä‘oÃ¡n: 100 â†’ Actual: 101 (Error = 1%)

Event days (COVID crash):
- Model dá»± Ä‘oÃ¡n: 100 â†’ Actual: 85 (Error = 15%)

â†’ Model KHÃ”NG há»c Ä‘Æ°á»£c pattern cá»§a crash
   vÃ¬ chá»‰ cÃ³ vÃ i ngÃ y crash trong 10 nÄƒm data!
```

### ğŸ’¡ Giáº£i phÃ¡p

> **Event-Aware Training: ÄÃ¡nh trá»ng sá»‘ CAO HÆ N cho event days**

```
Loss = Î£ weight(i) Ã— (y_pred(i) - y_true(i))Â²

Trong Ä‘Ã³:
- weight = 1.0 cho normal days
- weight = 5.0 cho event days

â†’ Model pháº£i há»c tá»‘t cáº£ normal vÃ  event days!
```

---

## 2. EVENT-AWARE TRAINING LÃ€ GÃŒ?

### ğŸ¯ Äá»‹nh nghÄ©a

> **Event-Aware Training = Training vá»›i weighted loss, Ä‘Ã¡nh trá»ng sá»‘ cao hÆ¡n cho nhá»¯ng ngÃ y cÃ³ sá»± kiá»‡n quan trá»ng**

### ğŸ“Š So sÃ¡nh

**Traditional Training:**
```
Day 1 (normal):  Loss = 0.01, Weight = 1.0 â†’ Weighted Loss = 0.01
Day 2 (normal):  Loss = 0.02, Weight = 1.0 â†’ Weighted Loss = 0.02
Day 3 (event):   Loss = 1.00, Weight = 1.0 â†’ Weighted Loss = 1.00
Day 4 (normal):  Loss = 0.01, Weight = 1.0 â†’ Weighted Loss = 0.01

Average Loss = (0.01 + 0.02 + 1.00 + 0.01) / 4 = 0.26
```

**Event-Aware Training:**
```
Day 1 (normal):  Loss = 0.01, Weight = 1.0 â†’ Weighted Loss = 0.01
Day 2 (normal):  Loss = 0.02, Weight = 1.0 â†’ Weighted Loss = 0.02
Day 3 (event):   Loss = 1.00, Weight = 5.0 â†’ Weighted Loss = 5.00 âš ï¸
Day 4 (normal):  Loss = 0.01, Weight = 1.0 â†’ Weighted Loss = 0.01

Average Loss = (0.01 + 0.02 + 5.00 + 0.01) / 4 = 1.26

â†’ Model Báº®T BUá»˜C pháº£i há»c tá»‘t event days!
```

### ğŸ’¡ Lá»£i Ã­ch

1. **Dá»± Ä‘oÃ¡n tá»‘t hÆ¡n trÃªn event days**
2. **PhÃ¡t hiá»‡n sá»›m shocks/anomalies**
3. **Risk management tá»‘t hÆ¡n**
4. **ÄÃ³ng gÃ³p nghiÃªn cá»©u má»›i** (Ã­t paper lÃ m Ä‘iá»u nÃ y!)

---

## 3. PHÃT HIá»†N EVENT DAYS

### ğŸ¯ Äá»‹nh nghÄ©a Event Day

**Event Day = NgÃ y cÃ³ biáº¿n Ä‘á»™ng Báº¤T THÆ¯á»œNG**

**TiÃªu chÃ­:**
1. **Price shock:** Return > 3Ïƒ (3 standard deviations)
2. **Volume spike:** Volume > 2Ã— average
3. **Volatility spike:** Volatility > 2Ã— average
4. **News event:** CÃ³ tin tá»©c quan trá»ng
5. **Filing event:** CÃ³ bÃ¡o cÃ¡o tÃ i chÃ­nh

### ğŸ“Š Method 1: Statistical Detection

**Dá»±a vÃ o Price:**
```python
def detect_price_events(df, threshold=3):
    """
    PhÃ¡t hiá»‡n event dá»±a vÃ o price returns
    
    Args:
        df: DataFrame vá»›i cá»™t 'return_1d'
        threshold: Sá»‘ standard deviations (default: 3)
    
    Returns:
        Boolean series: True = event day
    """
    returns = df['return_1d']
    mean = returns.mean()
    std = returns.std()
    
    # Event = return vÆ°á»£t quÃ¡ threshold Ã— std
    upper_bound = mean + threshold * std
    lower_bound = mean - threshold * std
    
    is_event = (returns > upper_bound) | (returns < lower_bound)
    
    return is_event

# Sá»­ dá»¥ng
df['is_price_event'] = detect_price_events(df, threshold=3)
print(f"Detected {df['is_price_event'].sum()} price events")
```

**Dá»±a vÃ o Volume:**
```python
def detect_volume_events(df, threshold=2):
    """
    PhÃ¡t hiá»‡n event dá»±a vÃ o volume spike
    
    Args:
        df: DataFrame vá»›i cá»™t 'volume' vÃ  'volume_ma_20'
        threshold: Multiplier (default: 2)
    
    Returns:
        Boolean series: True = event day
    """
    # Volume ratio = volume / moving average
    volume_ratio = df['volume'] / df['volume_ma_20']
    
    # Event = volume > threshold Ã— average
    is_event = volume_ratio > threshold
    
    return is_event

# Sá»­ dá»¥ng
df['is_volume_event'] = detect_volume_events(df, threshold=2)
print(f"Detected {df['is_volume_event'].sum()} volume events")
```

**Dá»±a vÃ o Volatility:**
```python
def detect_volatility_events(df, window=20, threshold=2):
    """
    PhÃ¡t hiá»‡n event dá»±a vÃ o volatility spike
    
    Args:
        df: DataFrame vá»›i cá»™t 'return_1d'
        window: Window cho rolling volatility
        threshold: Multiplier (default: 2)
    
    Returns:
        Boolean series: True = event day
    """
    # TÃ­nh rolling volatility
    returns = df['return_1d']
    rolling_vol = returns.rolling(window=window).std()
    
    # TÃ­nh average volatility
    avg_vol = rolling_vol.mean()
    
    # Event = volatility > threshold Ã— average
    is_event = rolling_vol > threshold * avg_vol
    
    return is_event

# Sá»­ dá»¥ng
df['is_vol_event'] = detect_volatility_events(df, window=20, threshold=2)
print(f"Detected {df['is_vol_event'].sum()} volatility events")
```

### ğŸ“Š Method 2: Composite Score

**Káº¿t há»£p nhiá»u signals:**
```python
def detect_events_composite(df, 
                           price_threshold=3,
                           volume_threshold=2,
                           vol_threshold=2,
                           min_score=2):
    """
    PhÃ¡t hiá»‡n events báº±ng composite score
    
    Event = Ã­t nháº¥t min_score signals kÃ­ch hoáº¡t
    
    Args:
        df: DataFrame
        price_threshold: Threshold cho price
        volume_threshold: Threshold cho volume
        vol_threshold: Threshold cho volatility
        min_score: Sá»‘ signals tá»‘i thiá»ƒu (default: 2)
    
    Returns:
        Boolean series: True = event day
    """
    # Detect tá»«ng loáº¡i
    price_event = detect_price_events(df, price_threshold)
    volume_event = detect_volume_events(df, volume_threshold)
    vol_event = detect_volatility_events(df, 20, vol_threshold)
    
    # TÃ­nh score (sá»‘ signals kÃ­ch hoáº¡t)
    score = price_event.astype(int) + volume_event.astype(int) + vol_event.astype(int)
    
    # Event = score >= min_score
    is_event = score >= min_score
    
    return is_event, score

# Sá»­ dá»¥ng
df['is_event'], df['event_score'] = detect_events_composite(df, min_score=2)

print(f"\n=== EVENT DETECTION SUMMARY ===")
print(f"Total days: {len(df)}")
print(f"Event days: {df['is_event'].sum()} ({df['is_event'].mean()*100:.2f}%)")
print(f"\nEvent score distribution:")
print(df['event_score'].value_counts().sort_index())
```

### ğŸ“Š Method 3: Machine Learning Detection

**Train model phÃ¡t hiá»‡n anomalies:**
```python
from sklearn.ensemble import IsolationForest

def detect_events_ml(df, contamination=0.05):
    """
    PhÃ¡t hiá»‡n events báº±ng Isolation Forest
    
    Args:
        df: DataFrame
        contamination: Tá»· lá»‡ anomalies dá»± kiáº¿n (default: 5%)
    
    Returns:
        Boolean series: True = event day
    """
    # Features cho anomaly detection
    features = ['return_1d', 'volume_ratio', 'volatility_20', 
                'rsi_14', 'daily_range_pct']
    X = df[features].dropna()
    
    # Train Isolation Forest
    model = IsolationForest(contamination=contamination, random_state=42)
    predictions = model.fit_predict(X)
    
    # -1 = anomaly, 1 = normal
    is_event = predictions == -1
    
    return pd.Series(is_event, index=X.index)

# Sá»­ dá»¥ng
df['is_ml_event'] = detect_events_ml(df, contamination=0.05)
print(f"Detected {df['is_ml_event'].sum()} ML events")
```

### ğŸ’¡ Visualize Events

```python
import matplotlib.pyplot as plt

def visualize_events(df, event_col='is_event'):
    """
    Visualize events trÃªn price chart
    """
    fig, axes = plt.subplots(3, 1, figsize=(14, 10))
    
    # Price chart vá»›i event markers
    axes[0].plot(df.index, df['close'], label='Close Price', alpha=0.7)
    event_days = df[df[event_col]]
    axes[0].scatter(event_days.index, event_days['close'], 
                   color='red', s=50, label='Event Days', zorder=5)
    axes[0].set_title('Price with Event Days')
    axes[0].set_ylabel('Price')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # Returns
    axes[1].plot(df.index, df['return_1d'], label='Returns', alpha=0.7)
    axes[1].scatter(event_days.index, event_days['return_1d'], 
                   color='red', s=50, label='Event Days', zorder=5)
    axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.3)
    axes[1].set_title('Returns with Event Days')
    axes[1].set_ylabel('Returns (%)')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    # Volume
    axes[2].bar(df.index, df['volume'], label='Volume', alpha=0.7)
    axes[2].scatter(event_days.index, event_days['volume'], 
                   color='red', s=50, label='Event Days', zorder=5)
    axes[2].set_title('Volume with Event Days')
    axes[2].set_ylabel('Volume')
    axes[2].set_xlabel('Date')
    axes[2].legend()
    axes[2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('event_detection.png', dpi=300)
    plt.show()

# Visualize
visualize_events(df, event_col='is_event')
```

---

## 4. WEIGHTED LOSS FUNCTIONS

### ğŸ¯ Weighted MSE

**CÃ´ng thá»©c:**
```
Weighted MSE = (1/n) Ã— Î£ w(i) Ã— (y_pred(i) - y_true(i))Â²

Trong Ä‘Ã³:
- w(i) = weight cho sample i
- w(i) = 1.0 cho normal days
- w(i) = k > 1.0 cho event days (k = 3, 5, 10, ...)
```

**Implementation:**
```python
def weighted_mse_loss(y_true, y_pred, weights):
    """
    Weighted MSE loss
    
    Args:
        y_true: True values
        y_pred: Predictions
        weights: Sample weights
    
    Returns:
        Weighted MSE
    """
    squared_errors = (y_true - y_pred) ** 2
    weighted_errors = weights * squared_errors
    return np.mean(weighted_errors)

# VÃ­ dá»¥
y_true = np.array([100, 102, 85, 103])  # Day 3 lÃ  event (85)
y_pred = np.array([101, 103, 95, 104])
weights = np.array([1.0, 1.0, 5.0, 1.0])  # Day 3 cÃ³ weight = 5.0

loss = weighted_mse_loss(y_true, y_pred, weights)
print(f"Weighted MSE: {loss:.2f}")

# So sÃ¡nh vá»›i MSE thÃ´ng thÆ°á»ng
normal_mse = np.mean((y_true - y_pred) ** 2)
print(f"Normal MSE: {normal_mse:.2f}")
```

### ğŸ”§ Weighted Loss cho PyTorch

```python
import torch
import torch.nn as nn

class WeightedMSELoss(nn.Module):
    """
    Weighted MSE Loss cho PyTorch
    """
    def __init__(self):
        super(WeightedMSELoss, self).__init__()
    
    def forward(self, y_pred, y_true, weights):
        """
        Args:
            y_pred: Predictions (batch_size, 1)
            y_true: True values (batch_size, 1)
            weights: Sample weights (batch_size, 1)
        
        Returns:
            Weighted MSE loss
        """
        squared_errors = (y_pred - y_true) ** 2
        weighted_errors = weights * squared_errors
        return torch.mean(weighted_errors)

# Sá»­ dá»¥ng
criterion = WeightedMSELoss()

# Trong training loop
for batch in dataloader:
    X, y, weights = batch
    
    # Forward
    y_pred = model(X)
    
    # Loss vá»›i weights
    loss = criterion(y_pred, y, weights)
    
    # Backward
    loss.backward()
    optimizer.step()
```

### ğŸ”§ Weighted Loss cho TensorFlow/Keras

```python
import tensorflow as tf

def weighted_mse_loss_tf(y_true, y_pred, weights):
    """
    Weighted MSE Loss cho TensorFlow
    """
    squared_errors = tf.square(y_true - y_pred)
    weighted_errors = weights * squared_errors
    return tf.reduce_mean(weighted_errors)

# Hoáº·c dÃ¹ng sample_weight trong fit()
model.fit(
    X_train, y_train,
    sample_weight=train_weights,  # â† Truyá»n weights vÃ o Ä‘Ã¢y
    epochs=100,
    batch_size=32
)
```

### ğŸ’¡ Chá»n Weight nhÆ° tháº¿ nÃ o?

**Strategy 1: Fixed Weights**
```python
def assign_fixed_weights(df, event_col='is_event', event_weight=5.0):
    """
    Fixed weight cho event days
    """
    weights = np.ones(len(df))
    weights[df[event_col]] = event_weight
    return weights

weights = assign_fixed_weights(df, event_weight=5.0)
```

**Strategy 2: Proportional Weights**
```python
def assign_proportional_weights(df, event_col='is_event'):
    """
    Weight tá»· lá»‡ nghá»‹ch vá»›i sá»‘ lÆ°á»£ng
    
    VÃ­ dá»¥:
    - Normal days: 95% â†’ weight = 1.0
    - Event days: 5% â†’ weight = 95/5 = 19.0
    """
    n_total = len(df)
    n_events = df[event_col].sum()
    n_normal = n_total - n_events
    
    event_weight = n_normal / n_events if n_events > 0 else 1.0
    
    weights = np.ones(len(df))
    weights[df[event_col]] = event_weight
    
    return weights

weights = assign_proportional_weights(df)
```

**Strategy 3: Score-Based Weights**
```python
def assign_score_based_weights(df, score_col='event_score', base_weight=1.0):
    """
    Weight dá»±a vÃ o event score
    
    Score 0: weight = 1.0
    Score 1: weight = 2.0
    Score 2: weight = 4.0
    Score 3: weight = 8.0
    """
    weights = base_weight * (2 ** df[score_col])
    return weights

weights = assign_score_based_weights(df)
```

---

## 5. EVENT-AWARE METRICS

### ğŸ¯ Táº¡i sao cáº§n Event-Aware Metrics?

**Váº¥n Ä‘á» vá»›i metrics thÃ´ng thÆ°á»ng:**
```
Overall MSE = 3.0 (trÃ´ng tá»‘t!)

NhÆ°ng:
- MSE trÃªn normal days = 1.0 (tá»‘t)
- MSE trÃªn event days = 15.0 (tá»‡!)

â†’ Model tá»‘t trÃªn normal, KÃ‰M trÃªn events
   nhÆ°ng overall MSE khÃ´ng pháº£n Ã¡nh Ä‘iá»u nÃ y!
```

### ğŸ“Š Event-Specific Metrics

**1. Separate Metrics cho Normal vs Event Days:**
```python
def evaluate_by_event(y_true, y_pred, is_event):
    """
    TÃ­nh metrics riÃªng cho normal vÃ  event days
    """
    from sklearn.metrics import mean_squared_error, mean_absolute_error
    
    # Normal days
    normal_mask = ~is_event
    mse_normal = mean_squared_error(y_true[normal_mask], y_pred[normal_mask])
    mae_normal = mean_absolute_error(y_true[normal_mask], y_pred[normal_mask])
    
    # Event days
    event_mask = is_event
    mse_event = mean_squared_error(y_true[event_mask], y_pred[event_mask])
    mae_event = mean_absolute_error(y_true[event_mask], y_pred[event_mask])
    
    # Overall
    mse_overall = mean_squared_error(y_true, y_pred)
    mae_overall = mean_absolute_error(y_true, y_pred)
    
    results = {
        'MSE_overall': mse_overall,
        'MSE_normal': mse_normal,
        'MSE_event': mse_event,
        'MAE_overall': mae_overall,
        'MAE_normal': mae_normal,
        'MAE_event': mae_event,
        'Event_ratio': is_event.mean()
    }
    
    return results

# Sá»­ dá»¥ng
results = evaluate_by_event(y_test, y_pred, test_is_event)

print("\n=== EVENT-AWARE EVALUATION ===")
for metric, value in results.items():
    print(f"{metric}: {value:.4f}")
```

**2. Tail Loss (Focus on Extreme Errors):**
```python
def tail_loss(y_true, y_pred, quantile=0.95):
    """
    Tail Loss: MSE chá»‰ tÃ­nh trÃªn errors lá»›n nháº¥t
    
    Args:
        y_true: True values
        y_pred: Predictions
        quantile: Quantile threshold (default: 0.95 = top 5% errors)
    
    Returns:
        Tail MSE
    """
    errors = np.abs(y_true - y_pred)
    threshold = np.quantile(errors, quantile)
    
    # Chá»‰ tÃ­nh MSE trÃªn errors > threshold
    tail_mask = errors > threshold
    tail_mse = np.mean((y_true[tail_mask] - y_pred[tail_mask]) ** 2)
    
    return tail_mse

# Sá»­ dá»¥ng
tail_mse = tail_loss(y_test, y_pred, quantile=0.95)
print(f"Tail MSE (top 5% errors): {tail_mse:.2f}")
```

**3. Direction Accuracy trÃªn Event Days:**
```python
def direction_accuracy_event(y_true, y_pred, is_event):
    """
    Direction accuracy: Dá»± Ä‘oÃ¡n Ä‘Ãºng hÆ°á»›ng tÄƒng/giáº£m
    TÃ­nh riÃªng cho event days
    """
    # TÃ­nh direction (1 = tÄƒng, 0 = giáº£m)
    true_direction = (y_true > 0).astype(int)
    pred_direction = (y_pred > 0).astype(int)
    
    # Accuracy trÃªn event days
    event_mask = is_event
    correct = (true_direction[event_mask] == pred_direction[event_mask])
    accuracy = correct.mean()
    
    return accuracy

# Sá»­ dá»¥ng
dir_acc = direction_accuracy_event(y_test_returns, y_pred_returns, test_is_event)
print(f"Direction Accuracy (event days): {dir_acc*100:.2f}%")
```

---

## 6. IMPLEMENTATION GUIDE

### ğŸ”§ Full Pipeline

**Step 1: Detect Events**
```python
# Detect events
df['is_event'], df['event_score'] = detect_events_composite(
    df, 
    price_threshold=3,
    volume_threshold=2,
    vol_threshold=2,
    min_score=2
)

print(f"Detected {df['is_event'].sum()} events ({df['is_event'].mean()*100:.2f}%)")
```

**Step 2: Assign Weights**
```python
# Assign weights
weights = assign_proportional_weights(df, event_col='is_event')

print(f"Normal weight: {weights[~df['is_event']].mean():.2f}")
print(f"Event weight: {weights[df['is_event']].mean():.2f}")
```

**Step 3: Prepare Data**
```python
# Features vÃ  target
feature_cols = ['close', 'ma_20', 'rsi_14', 'macd', 'volatility_20']
X = df[feature_cols]
y = df['close'].shift(-1)  # Target: giÃ¡ ngÃ y mai

# Combine
data = pd.concat([X, y.rename('target'), 
                  df['is_event'], 
                  pd.Series(weights, index=df.index, name='weight')], 
                 axis=1).dropna()

# Split
split_idx = int(len(data) * 0.8)
train_data = data[:split_idx]
test_data = data[split_idx:]

X_train = train_data[feature_cols]
y_train = train_data['target']
weights_train = train_data['weight']
is_event_train = train_data['is_event']

X_test = test_data[feature_cols]
y_test = test_data['target']
weights_test = test_data['weight']
is_event_test = test_data['is_event']
```

**Step 4: Train vá»›i Weighted Loss**
```python
# Option 1: sklearn vá»›i sample_weight
from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, y_train, sample_weight=weights_train)

# Option 2: Custom training loop
# (Xem pháº§n PyTorch/TensorFlow á»Ÿ trÃªn)
```

**Step 5: Evaluate**
```python
# Predictions
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# Event-aware evaluation
train_results = evaluate_by_event(y_train, y_pred_train, is_event_train)
test_results = evaluate_by_event(y_test, y_pred_test, is_event_test)

print("\n=== TRAINING RESULTS ===")
for metric, value in train_results.items():
    print(f"{metric}: {value:.4f}")

print("\n=== TEST RESULTS ===")
for metric, value in test_results.items():
    print(f"{metric}: {value:.4f}")

# Tail loss
tail_mse_train = tail_loss(y_train, y_pred_train, quantile=0.95)
tail_mse_test = tail_loss(y_test, y_pred_test, quantile=0.95)

print(f"\nTail MSE (train): {tail_mse_train:.2f}")
print(f"Tail MSE (test): {tail_mse_test:.2f}")
```

**Step 6: Compare vá»›i Baseline**
```python
# Train baseline (no weights)
baseline_model = LinearRegression()
baseline_model.fit(X_train, y_train)  # KhÃ´ng cÃ³ sample_weight

# Predictions
baseline_pred_test = baseline_model.predict(X_test)

# Compare
baseline_results = evaluate_by_event(y_test, baseline_pred_test, is_event_test)

print("\n=== COMPARISON ===")
print(f"{'Metric':<20} {'Baseline':<12} {'Event-Aware':<12} {'Improvement':<12}")
print("-" * 56)
for metric in ['MSE_overall', 'MSE_normal', 'MSE_event']:
    baseline_val = baseline_results[metric]
    event_aware_val = test_results[metric]
    improvement = (baseline_val - event_aware_val) / baseline_val * 100
    print(f"{metric:<20} {baseline_val:<12.4f} {event_aware_val:<12.4f} {improvement:>10.2f}%")
```

---

## 7. BÃ€I Táº¬P THá»°C HÃ€NH

### ğŸ¯ BÃ i táº­p 1: Event Detection

**Äá» bÃ i:**
Implement 3 methods phÃ¡t hiá»‡n events cho FPT:
1. Statistical (price + volume + volatility)
2. Composite score
3. Machine Learning (Isolation Forest)

**YÃªu cáº§u:**
- Detect events trÃªn toÃ n bá»™ data
- So sÃ¡nh 3 methods
- Visualize events
- PhÃ¢n tÃ­ch: Events cÃ³ overlap khÃ´ng? Method nÃ o tá»‘t nháº¥t?

**Kiá»ƒm tra:**
- [ ] Implement Ä‘Æ°á»£c 3 methods
- [ ] Detect Ä‘Æ°á»£c events
- [ ] Visualize Ä‘áº¹p
- [ ] PhÃ¢n tÃ­ch vÃ  so sÃ¡nh

---

### ğŸ¯ BÃ i táº­p 2: Event-Aware Training

**Äá» bÃ i:**
Train Linear Regression vá»›i event-aware loss

**YÃªu cáº§u:**
- Detect events
- Assign weights (thá»­ 3 strategies)
- Train vá»›i weighted loss
- So sÃ¡nh vá»›i baseline (no weights)
- Evaluate vá»›i event-aware metrics

**Kiá»ƒm tra:**
- [ ] Train Ä‘Æ°á»£c vá»›i weighted loss
- [ ] So sÃ¡nh Ä‘Æ°á»£c vá»›i baseline
- [ ] Chá»©ng minh Ä‘Æ°á»£c improvement trÃªn event days
- [ ] Viáº¿t bÃ¡o cÃ¡o phÃ¢n tÃ­ch

---

### ğŸ¯ BÃ i táº­p 3: Case Study - COVID Crash

**Äá» bÃ i:**
PhÃ¢n tÃ­ch performance cá»§a model trÃªn COVID crash (Feb-Mar 2020)

**YÃªu cáº§u:**
- Identify COVID crash period
- Train 2 models: Baseline vs Event-Aware
- Evaluate trÃªn crash period
- Visualize predictions vs actual
- PhÃ¢n tÃ­ch: Model nÃ o dá»± Ä‘oÃ¡n tá»‘t hÆ¡n? Táº¡i sao?

**Kiá»ƒm tra:**
- [ ] Identify Ä‘Æ°á»£c crash period
- [ ] Train Ä‘Æ°á»£c 2 models
- [ ] So sÃ¡nh performance
- [ ] Visualize vÃ  giáº£i thÃ­ch

---

## âœ… KIá»‚M TRA HIá»‚U BÃ€I

TrÆ°á»›c khi sang bÃ i tiáº¿p theo, hÃ£y Ä‘áº£m báº£o báº¡n:

- [ ] Hiá»ƒu váº¥n Ä‘á» vá»›i training thÃ´ng thÆ°á»ng
- [ ] Hiá»ƒu event-aware training lÃ  gÃ¬
- [ ] Implement Ä‘Æ°á»£c 3 methods phÃ¡t hiá»‡n events
- [ ] Implement Ä‘Æ°á»£c weighted loss
- [ ] Hiá»ƒu cÃ¡ch chá»n weights
- [ ] Implement Ä‘Æ°á»£c event-aware metrics
- [ ] Train Ä‘Æ°á»£c model vá»›i event-aware loss
- [ ] Chá»©ng minh Ä‘Æ°á»£c improvement
- [ ] LÃ m Ä‘Æ°á»£c 3 bÃ i táº­p thá»±c hÃ nh

**Náº¿u chÆ°a pass háº¿t checklist, Ä‘á»c láº¡i pháº§n tÆ°Æ¡ng á»©ng!**

---

## ğŸ“š TÃ€I LIá»†U THAM KHáº¢O

**Papers:**
- "Learning from Imbalanced Data" - He & Garcia (2009)
- "Cost-Sensitive Learning" - Elkan (2001)
- "Focal Loss for Dense Object Detection" - Lin et al. (2017)

**Related Work:**
- Hard Example Mining
- Curriculum Learning
- Importance Sampling

---

## ğŸš€ BÆ¯á»šC TIáº¾P THEO

Sau khi hoÃ n thÃ nh bÃ i nÃ y, sang:
- `02_REGIME_DETECTION.md` - PhÃ¡t hiá»‡n regime change
- `03_TAIL_RISK_METRICS.md` - Metrics cho tail events

**ChÃºc báº¡n há»c tá»‘t! ğŸ“**
