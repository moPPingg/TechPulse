# -*- coding: utf-8 -*-
"""
Script ƒë·ªÉ l·∫•y to√†n b·ªô 30 m√£ c·ªï phi·∫øu VN30 t·ª´ CafeF
v√† ch·∫°y full pipeline: Crawl ‚Üí Clean ‚Üí Features

Author: Auto-generated
Date: 2026-01-20
"""
import sys
import io

# Fix encoding cho Windows console
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from src.pipeline.runcrawler.run_crawler import crawl_many
from src.clean.clean_price import clean_many
from src.features.build_features import build_features
import logging

# ============================================================================
# C·∫§U H√åNH LOGGING
# ============================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# DANH S√ÅCH 30 M√É VN30 (C·∫≠p nh·∫≠t Q1/2026)
# ============================================================================
# L∆∞u √Ω: Danh s√°ch n√†y thay ƒë·ªïi m·ªói qu√Ω, c·∫ßn ki·ªÉm tra t·∫°i:
# https://www.hsx.vn/Modules/Listed/Web/SymbolList/faad6e1b-8646-48aa-8f6f-b6fc092d714d?fid=a938a51449064a84a7b9bd99bf49c97e
VN30_SYMBOLS = [
    'ACB',  # Ng√¢n h√†ng √Å Ch√¢u
    'BCM',  # Kho√°ng s·∫£n B·∫Øc C·∫°n
    'BID',  # Ng√¢n h√†ng BIDV
    'BVH',  # B·∫£o Vi·ªát Holdings
    'CTG',  # Ng√¢n h√†ng Vietinbank
    'FPT',  # FPT Corporation
    'GAS',  # PetroVietnam Gas
    'GVR',  # Cao su Vi·ªát Nam
    'HDB',  # Ng√¢n h√†ng HDBank
    'HPG',  # H√≤a Ph√°t Group
    'MBB',  # Ng√¢n h√†ng MB
    'MSN',  # Masan Group
    'MWG',  # Mobile World
    'PLX',  # Petrolimex
    'POW',  # PetroVietnam Power
    'SAB',  # Sabeco
    'SSI',  # SSI Securities
    'STB',  # Ng√¢n h√†ng Sacombank
    'TCB',  # Ng√¢n h√†ng Techcombank
    'TPB',  # Ng√¢n h√†ng TPBank
    'VCB',  # Ng√¢n h√†ng Vietcombank
    'VHM',  # Vinhomes
    'VIB',  # Ng√¢n h√†ng VIB
    'VIC',  # Vingroup
    'VJC',  # Vietjet Air
    'VNM',  # Vinamilk
    'VPB',  # Ng√¢n h√†ng VPBank
    'VRE',  # Vincom Retail
    'SSB',  # Ng√¢n h√†ng SeABank
    'PDR',  # Ph√°t ƒê·∫°t
]


def run_vn30_pipeline(
    start_date: str,
    end_date: str,
    raw_dir: str = 'data/raw/vn30',
    clean_dir: str = 'data/clean/vn30',
    features_dir: str = 'data/features/vn30'
):
    """
    Ch·∫°y to√†n b·ªô pipeline cho VN30: Crawl ‚Üí Clean ‚Üí Features
    
    Pipeline g·ªìm 3 b∆∞·ªõc:
    1. CRAWL: L·∫•y d·ªØ li·ªáu t·ª´ CafeF API
    2. CLEAN: L√†m s·∫°ch, validate data quality
    3. FEATURES: T√≠nh to√°n technical indicators
    
    Args:
        start_date: Ng√†y b·∫Øt ƒë·∫ßu, format 'DD/MM/YYYY' (vd: '01/01/2024')
        end_date: Ng√†y k·∫øt th√∫c, format 'DD/MM/YYYY' (vd: '31/12/2024')
        raw_dir: Th∆∞ m·ª•c l∆∞u raw data (default: 'data/raw/vn30')
        clean_dir: Th∆∞ m·ª•c l∆∞u clean data (default: 'data/clean/vn30')
        features_dir: Th∆∞ m·ª•c l∆∞u features (default: 'data/features/vn30')
    
    Returns:
        None (l∆∞u files v√†o disk)
    
    Example:
        >>> run_vn30_pipeline('01/01/2024', '31/12/2024')
        # S·∫Ω t·∫°o 90 files (30 raw + 30 clean + 30 features)
    """
    logger.info("=" * 80)
    logger.info("üöÄ B·∫ÆT ƒê·∫¶U PIPELINE VN30")
    logger.info("=" * 80)
    logger.info(f"üìÖ Kho·∫£ng th·ªùi gian: {start_date} ‚Üí {end_date}")
    logger.info(f"üìä T·ªïng s·ªë m√£: {len(VN30_SYMBOLS)}")
    
    # ========================================================================
    # B∆Ø·ªöC 1: CRAWL D·ªÆ LI·ªÜU T·ª™ CAFEF
    # ========================================================================
    logger.info("\n" + "=" * 80)
    logger.info("üì• B∆Ø·ªöC 1/3: CRAWL D·ªÆ LI·ªÜU VN30")
    logger.info("=" * 80)
    logger.info("ƒêang g·ªçi API CafeF ƒë·ªÉ l·∫•y d·ªØ li·ªáu l·ªãch s·ª≠...")
    
    try:
        raw_results = crawl_many(
            symbols=VN30_SYMBOLS,
            start_date=start_date,
            end_date=end_date,
            save_dir=raw_dir,
            combine=True,        # T·∫°o th√™m file combined ch·ª©a t·∫•t c·∫£ m√£
            skip_on_error=True   # Ti·∫øp t·ª•c n·∫øu 1 m√£ b·ªã l·ªói
        )
        
        logger.info(f"‚úÖ Crawl ho√†n t·∫•t: {len(raw_results)}/{len(VN30_SYMBOLS)} m√£ th√†nh c√¥ng")
        
        if not raw_results:
            logger.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c crawl. D·ª´ng pipeline.")
            logger.error("Nguy√™n nh√¢n c√≥ th·ªÉ:")
            logger.error("  - Kh√¥ng c√≥ k·∫øt n·ªëi Internet")
            logger.error("  - API CafeF ƒëang b·∫£o tr√¨")
            logger.error("  - Kho·∫£ng ng√†y kh√¥ng h·ª£p l·ªá")
            return
            
    except Exception as e:
        logger.error(f"‚ùå L·ªói trong qu√° tr√¨nh crawl: {e}")
        return
    
    # ========================================================================
    # B∆Ø·ªöC 2: CLEAN D·ªÆ LI·ªÜU
    # ========================================================================
    logger.info("\n" + "=" * 80)
    logger.info("üßπ B∆Ø·ªöC 2/3: CLEAN V√Ä VALIDATE D·ªÆ LI·ªÜU")
    logger.info("=" * 80)
    logger.info("ƒêang l√†m s·∫°ch d·ªØ li·ªáu:")
    logger.info("  - Lo·∫°i b·ªè duplicates")
    logger.info("  - Lo·∫°i b·ªè null values")
    logger.info("  - Validate OHLC logic")
    logger.info("  - Ki·ªÉm tra gi√° √¢m, gi√° = 0")
    
    try:
        clean_results = clean_many(
            raw_dir=raw_dir,
            clean_dir=clean_dir,
            skip_on_error=True,
            remove_duplicates=True,
            remove_nulls=True,
            validate=True
        )
        
        logger.info(f"‚úÖ Clean ho√†n t·∫•t: {len(clean_results)} files")
        
        if not clean_results:
            logger.warning("‚ö†Ô∏è  Kh√¥ng c√≥ file clean ƒë∆∞·ª£c. B·ªè qua b∆∞·ªõc features.")
            return
            
    except Exception as e:
        logger.error(f"‚ùå L·ªói trong qu√° tr√¨nh clean: {e}")
        return
    
    # ========================================================================
    # B∆Ø·ªöC 3: BUILD FEATURES (TECHNICAL INDICATORS)
    # ========================================================================
    logger.info("\n" + "=" * 80)
    logger.info("‚öôÔ∏è  B∆Ø·ªöC 3/3: BUILD TECHNICAL FEATURES")
    logger.info("=" * 80)
    logger.info("ƒêang t√≠nh to√°n c√°c ch·ªâ s·ªë k·ªπ thu·∫≠t:")
    logger.info("  - Returns (1d, 5d, 10d, 20d)")
    logger.info("  - Moving Averages (MA5, MA10, MA20, MA50)")
    logger.info("  - EMA (12, 26)")
    logger.info("  - Volatility (5d, 10d, 20d)")
    logger.info("  - RSI (14)")
    logger.info("  - MACD, Signal, Histogram")
    logger.info("  - Bollinger Bands (upper, middle, lower, width)")
    logger.info("  - Volume features")
    logger.info("  - Momentum indicators")
    logger.info("  - Price range & ATR")
    
    try:
        feature_results = build_features(
            clean_dir=clean_dir,
            features_dir=features_dir,
            skip_on_error=True,
            drop_na=True
        )
        
        logger.info(f"‚úÖ Features ho√†n t·∫•t: {len(feature_results)} files")
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói trong qu√° tr√¨nh build features: {e}")
        return
    
    # ========================================================================
    # T·ªîNG K·∫æT K·∫æT QU·∫¢
    # ========================================================================
    logger.info("\n" + "=" * 80)
    logger.info("üéâ HO√ÄN TH√ÄNH PIPELINE VN30")
    logger.info("=" * 80)
    logger.info(f"üìÅ Raw data:     {len(raw_results)} files ‚Üí {raw_dir}/")
    logger.info(f"üìÅ Clean data:   {len(clean_results)} files ‚Üí {clean_dir}/")
    logger.info(f"üìÅ Features:     {len(feature_results)} files ‚Üí {features_dir}/")
    logger.info("=" * 80)
    
    # Hi·ªÉn th·ªã sample c·ªßa 1 file features
    if feature_results:
        sample_file = list(feature_results.keys())[0]
        sample_df = feature_results[sample_file]
        logger.info(f"\nüìä Sample features t·ª´ {sample_file}:")
        logger.info(f"   - T·ªïng s·ªë d√≤ng: {len(sample_df)}")
        logger.info(f"   - T·ªïng s·ªë c·ªôt: {len(sample_df.columns)}")
        logger.info(f"   - Columns: {list(sample_df.columns[:10])}...")
    
    logger.info("\n‚úÖ B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng data cho:")
    logger.info("   1. Machine Learning (prediction)")
    logger.info("   2. Technical Analysis")
    logger.info("   3. Backtesting trading strategies")
    logger.info("   4. Data visualization")


def fetch_vn30_only(
    start_date: str,
    end_date: str,
    save_dir: str = 'data/raw/vn30'
):
    """
    Ch·ªâ crawl VN30 (KH√îNG clean, KH√îNG t√≠nh features)
    
    D√πng khi:
    - B·∫°n ch·ªâ c·∫ßn raw data
    - Mu·ªën t·ª± x·ª≠ l√Ω data theo c√°ch ri√™ng
    - Crawl nhanh ƒë·ªÉ ki·ªÉm tra
    
    Args:
        start_date: Ng√†y b·∫Øt ƒë·∫ßu, format 'DD/MM/YYYY'
        end_date: Ng√†y k·∫øt th√∫c, format 'DD/MM/YYYY'
        save_dir: Th∆∞ m·ª•c l∆∞u (default: 'data/raw/vn30')
    
    Returns:
        List of DataFrames (m·ªói m√£ 1 DataFrame)
    
    Example:
        >>> data = fetch_vn30_only('01/01/2024', '31/12/2024')
        >>> print(f"L·∫•y ƒë∆∞·ª£c {len(data)} m√£")
        >>> # Xem data c·ªßa FPT
        >>> fpt_data = [df for df in data if df['ticker'].iloc[0] == 'FPT'][0]
        >>> print(fpt_data.head())
    """
    logger.info("=" * 80)
    logger.info("üì• CRAWLING VN30 (CH·ªà RAW DATA)")
    logger.info("=" * 80)
    logger.info(f"T·ªïng s·ªë m√£: {len(VN30_SYMBOLS)}")
    logger.info(f"Kho·∫£ng th·ªùi gian: {start_date} ‚Üí {end_date}")
    
    results = crawl_many(
        symbols=VN30_SYMBOLS,
        start_date=start_date,
        end_date=end_date,
        save_dir=save_dir,
        combine=True,
        skip_on_error=True
    )
    
    logger.info("\n" + "=" * 80)
    logger.info(f"‚úÖ HO√ÄN TH√ÄNH! ƒê√£ l·∫•y {len(results)}/{len(VN30_SYMBOLS)} m√£ VN30")
    logger.info(f"üìÅ Files ƒë∆∞·ª£c l∆∞u t·∫°i: {save_dir}/")
    logger.info("=" * 80)
    
    return results


def update_vn30_symbols(new_symbols: list):
    """
    C·∫≠p nh·∫≠t danh s√°ch VN30 (thay ƒë·ªïi m·ªói qu√Ω)
    
    Args:
        new_symbols: List c√°c m√£ m·ªõi (ph·∫£i c√≥ ƒë√∫ng 30 m√£)
    
    Example:
        >>> new_list = ['ACB', 'BID', 'CTG', ...]  # 30 m√£
        >>> update_vn30_symbols(new_list)
    """
    global VN30_SYMBOLS
    
    if len(new_symbols) != 30:
        logger.error(f"‚ùå VN30 ph·∫£i c√≥ ƒë√∫ng 30 m√£. B·∫°n cung c·∫•p {len(new_symbols)} m√£.")
        return False
    
    VN30_SYMBOLS = [symbol.upper().strip() for symbol in new_symbols]
    logger.info(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t danh s√°ch VN30: {VN30_SYMBOLS}")
    return True


# ============================================================================
# MAIN - CH·∫†Y KHI EXECUTE FILE TR·ª∞C TI·∫æP
# ============================================================================
if __name__ == "__main__":
    """
    C√≥ 2 c√°ch s·ª≠ d·ª•ng:
    
    C√ÅCH 1: Ch·ªâ crawl raw data (nhanh, ~2 ph√∫t)
    C√ÅCH 2: Ch·∫°y full pipeline (l√¢u h∆°n, ~5-10 ph√∫t)
    
    Uncomment c√°ch n√†o b·∫°n mu·ªën d√πng ·ªü d∆∞·ªõi
    """
    
    # ========================================================================
    # C√ÅCH 1: CH·ªà CRAWL RAW DATA (Nhanh nh·∫•t)
    # ========================================================================
    # Uncomment 2 d√≤ng d∆∞·ªõi ƒë·ªÉ ch·∫°y
    # print("\nüîπ Ch·∫ø ƒë·ªô: CH·ªà CRAWL RAW DATA")
    # fetch_vn30_only('01/01/2024', '20/01/2026')
    
    
    # ========================================================================
    # C√ÅCH 2: CH·∫†Y FULL PIPELINE (Crawl ‚Üí Clean ‚Üí Features)
    # ========================================================================
    # Uncomment 2 d√≤ng d∆∞·ªõi ƒë·ªÉ ch·∫°y
    print("\nüîπ Ch·∫ø ƒë·ªô: FULL PIPELINE (Crawl + Clean + Features)")
    run_vn30_pipeline(
        start_date='01/01/2024',
        end_date='20/01/2026'
    )
    
    
    # ========================================================================
    # T√ôY CH·ªåN: Thay ƒë·ªïi th∆∞ m·ª•c l∆∞u
    # ========================================================================
    # run_vn30_pipeline(
    #     start_date='01/01/2024',
    #     end_date='20/01/2026',
    #     raw_dir='my_data/raw',
    #     clean_dir='my_data/clean',
    #     features_dir='my_data/features'
    # )
